{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Easy Feature Extraction\n",
    "\n",
    "The purpose of this notebook is to provide \"one click\" solution to reproducing the dataset.  Note, this assumes that you are building dataset from the enclosed .csv files rather than web scraping and calling pushshift.io APIs.  If you want to build .csv files use the notebooks for getting the data into .csv files first:\n",
    "\n",
    "- reddit2db.ipynb - calls Pushshift.io APIs and stored output in MongoDB.  The instructions on how to run MongoDB are included inside of the notebook.\n",
    "- reddit_db_2_csv.ipynb - queries database and saves only relevant information in to .csv file.\n",
    "- migraine.com_data.ipynb - web scrapes Migraine.com and stores the data in .csv file.\n",
    "- tbd.wbsite.com_data.ipynb - TBD\n",
    "\n",
    "## Note\n",
    "\n",
    "Before running make sure that the cell below was executed once in your environment.  This download is needed fro Spacy library and it should be downloaded once.\n",
    "\n",
    "For subsequent runs this should stay commented out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import unittest\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddis_data_filename = 'reddis_migraine_posts.csv'\n",
    "migraine_dot_com = 'migraine.com.csv'\n",
    "patient_info_com = 'patient.info.csv'\n",
    "csv_files = [reddis_data_filename, migraine_dot_com, patient_info_com]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_reddis_data(files):\n",
    "    dfs = []\n",
    "    for file in files:\n",
    "        dfs.append(pd.read_csv(f'data/{file}', header=0))\n",
    "        df = pd.concat(dfs)\n",
    "        df = df.dropna(subset=['Text'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_and_commnets = read_reddis_data(csv_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_and_commnets = list(posts_and_commnets[['Author', 'Text']].to_records(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipe(functions):\n",
    "    def run_pipe(input):\n",
    "        result = input\n",
    "        for function in functions:\n",
    "            result = function(result)\n",
    "        return result\n",
    "    return run_pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Author Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author index\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "author_index = defaultdict(dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gender Discovery Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex patterns\n",
    "male_matchers = [\n",
    "    re.compile('my\\s+wife', re.IGNORECASE),\n",
    "    re.compile('my\\s.*girlfriend', re.IGNORECASE),\n",
    "    re.compile('\\s[0-9][0-9](m\\s|\\(m\\)|\\s\\(m\\))', re.IGNORECASE),\n",
    "    re.compile('\\s[0-9][0-9].*male', re.IGNORECASE),\n",
    "    re.compile('male.*[0-9][0-9]', re.IGNORECASE)\n",
    "]\n",
    "\n",
    "female_matchers = [\n",
    "    re.compile('my\\s+husband', re.IGNORECASE),\n",
    "    re.compile('I( am|\\'m)\\s.*pregnant', re.IGNORECASE),\n",
    "    re.compile('I\\s.*menstruation', re.IGNORECASE),\n",
    "    re.compile('my\\s.*boyfriend', re.IGNORECASE),\n",
    "    re.compile('\\s[0-9][0-9](f|\\(f\\)|\\s\\(f\\))', re.IGNORECASE),\n",
    "    re.compile('\\s[0-9][0-9].*female', re.IGNORECASE),\n",
    "    re.compile('female.*[0-9][0-9]', re.IGNORECASE)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender discovery functions\n",
    "def discover_gender(matchers):\n",
    "    def find_in_text(text):\n",
    "        return any([\n",
    "            matcher.search(text) for matcher in matchers\n",
    "        ])\n",
    "    return find_in_text\n",
    "\n",
    "find_females = discover_gender(female_matchers)\n",
    "find_males = discover_gender(male_matchers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_gender(text):\n",
    "    if find_males(text):\n",
    "        return 'male'\n",
    "    elif find_females(text):\n",
    "        return 'female'\n",
    "    return 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_gender_in_posts(idx):\n",
    "    gender_idx = copy.deepcopy(idx)\n",
    "    def process_entry(author, text):\n",
    "        gender_idx[author]['gender'] = identify_gender(text)\n",
    "\n",
    "    for author, text in posts_and_commnets:\n",
    "        process_entry(author, text)\n",
    "    return gender_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Medicine Information Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_list = [\n",
    "    'Amitriptyline',\n",
    "    'Elavil',\n",
    "    'Divalproex',\n",
    "    'Depakote',\n",
    "    'Eletriptan',\n",
    "    'Relpax',\n",
    "    'triptan',\n",
    "    'Metoprolol',\n",
    "    'Lopressor',\n",
    "    'Toprol',\n",
    "    'Propranolol',\n",
    "    'Inderal',\n",
    "    'beta blocker',\n",
    "    'Rizatriptan',\n",
    "    'Maxalt',\n",
    "    'Sumatriptan',\n",
    "    'Imitrex',\n",
    "    'Topiramate',\n",
    "    'Topamax',\n",
    "    'Trokendi',\n",
    "    'Venlafaxine',\n",
    "    'Effexor',\n",
    "    'Zolmitriptan',\n",
    "    'Zomig',\n",
    "    'OnabotulinumtoxinA',\n",
    "    'Botox',\n",
    "    'Erenumab',\n",
    "    'Aimovig',\n",
    "    'CGRP',\n",
    "    'Nurtec',  # found in the subreddit post\n",
    "    'Topomax',  # popular misspelling of Topamax,\n",
    "    'nortiptyline',  # found in the subreddit post\n",
    "    'metoclopramide',  # found in the subreddit post\n",
    "    'caffeine pill',  # found in the subreddit posts_and_comments\n",
    "    'naproxen',\n",
    "    'magnesium',\n",
    "    'Delta 8',\n",
    "    'Aimovig',\n",
    "    'sulfate',\n",
    "    'Xanax',\n",
    "    'amitryptiline',\n",
    "    'Amoxicillin'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regex patterns\n",
    "drug_matchers = [\n",
    "    {\n",
    "        'regex': re.compile('([0-9]x).*([0-9]+\\.?[0-9]+mg|[0-9]+\\.?[0-9]+\\smg|\\.?[0-9]+mg|\\.?[0-9]+\\smg)', flags=re.IGNORECASE),\n",
    "        'dosage_group': 2,\n",
    "        'qty_group': 1\n",
    "    },\n",
    "    {\n",
    "        'regex': re.compile('([0-9]+\\.?[0-9]+mg|[0-9]+\\.?[0-9]+\\smg|\\.?[0-9]+mg|\\.?[0-9]+\\smg).*([0-9]x)', flags=re.IGNORECASE),\n",
    "        'dosage_group': 1,\n",
    "        'qty_group': 2\n",
    "    },\n",
    "    {\n",
    "        'regex': re.compile('([0-9]+\\.?[0-9]+mg|[0-9]+\\.?[0-9]+\\smg|\\.?[0-9]+mg|\\.?[0-9]+\\smg).*(three times a day|four times a day|twice a day|one a day|twice daily)', flags=re.IGNORECASE),\n",
    "        'dosage_group': 1,\n",
    "        'qty_group': 2\n",
    "    },\n",
    "    {\n",
    "        'regex': re.compile('([0-9]+mg|[0-9]+\\smg).*(nightly|daily|dose|day)', flags=re.IGNORECASE),\n",
    "        'dosage_group': 1,\n",
    "        'qty_group': 2\n",
    "    },\n",
    "    {\n",
    "        'regex': re.compile('([0-9]+\\.?[0-9]+mg|[0-9]+\\.?[0-9]+\\smg|\\.?[0-9]+mg|\\.?[0-9]+\\smg)', flags=re.IGNORECASE),\n",
    "        'dosage_group': 1,\n",
    "        'qty_group': -1\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Medicine discovery functions\n",
    "def normalize_qty(qty_text):\n",
    "    if qty_text == 'daily' or qty_text == 'dose' or qty_text == 'day' or qty_text == 'one a day' or qty_text == '1x':\n",
    "        return '1x'\n",
    "\n",
    "    if qty_text == 'twice daily' or qty_text == 'twice a day':\n",
    "        return '2x'\n",
    "\n",
    "    if qty_text == 'three times a day':\n",
    "        return '3x'\n",
    "\n",
    "    return qty_text\n",
    "\n",
    "def find_medicine_name(text):\n",
    "    meds_matched = []\n",
    "    for drug in drug_list:\n",
    "        if re.search(drug, text, re.IGNORECASE):\n",
    "            meds_matched.append(drug)\n",
    "    return meds_matched\n",
    "\n",
    "def find_dosage(reg_res, matcher):\n",
    "    if matcher['qty_group'] == -1:\n",
    "        qty = '1x'\n",
    "    else:\n",
    "        qty = normalize_qty(reg_res.group(matcher['qty_group']))\n",
    "    return reg_res.group(matcher['dosage_group']), qty\n",
    "\n",
    "def discover_medicine_dosage(matchers):\n",
    "    def process_medicine_dosage(text):\n",
    "        for matcher in matchers:\n",
    "            if (reg_res := matcher['regex'].search(text)):\n",
    "                dosage, qty = find_dosage(reg_res, matcher)\n",
    "                if dosage:\n",
    "                    med = find_medicine_name(text)\n",
    "                    if med:\n",
    "                        return (\n",
    "                            med[0],\n",
    "                            dosage,\n",
    "                            qty\n",
    "                        )\n",
    "\n",
    "        return 'unknown', 'unknown', 'unknown'\n",
    "    return process_medicine_dosage\n",
    "\n",
    "find_medicine_dosage = discover_medicine_dosage(drug_matchers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_medicine_in_posts(idx):\n",
    "    medicine_idx = copy.deepcopy(idx)\n",
    "    def process_entry(author, text):\n",
    "        med, dosage, qty = find_medicine_dosage(text)\n",
    "        medicine_idx[author]['medicine'] = med\n",
    "        medicine_idx[author]['dosage'] = dosage\n",
    "        medicine_idx[author]['qty'] = qty\n",
    "\n",
    "    for author, text in posts_and_commnets:\n",
    "        process_entry(author, text)\n",
    "    return medicine_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suicidal Thoughts Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regex expressions\n",
    "positive_suicide_matchers = [\n",
    "    re.compile('(am|have|had|felt|having|me|was|been|think|about|feeling).*(suicidal|suicide)', re.IGNORECASE),\n",
    "    re.compile('(my near|made me|have been|thought about|).*(suicidal|suicide)', re.IGNORECASE)\n",
    "]\n",
    "\n",
    "negative_suicide_matchers = [\n",
    "    re.compile('(am|have|had|felt|having|me|was|been|think|about|feeling) (not|never).*(suicidal|suicide)', re.IGNORECASE),\n",
    "    re.compile('(my near|made me|have been|thought about|) (not|never).*(suicidal|suicide)', re.IGNORECASE)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_for_suicide(text):\n",
    "    return any([matcher.search(text) for matcher in positive_suicide_matchers]) \\\n",
    "        and not any([matcher.search(text) for matcher in negative_suicide_matchers])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_suicidal_thoughts_in_posts(idx):\n",
    "    suicidal_thoughts_idx = copy.deepcopy(idx)\n",
    "    def process_entry(author, text):\n",
    "        if search_for_suicide(text):\n",
    "            suicidal_thoughts_idx[author]['suicidal'] = 'yes'\n",
    "        else:\n",
    "            suicidal_thoughts_idx[author]['suicidal'] = 'no'\n",
    "\n",
    "    for author, text in posts_and_commnets:\n",
    "        process_entry(author, text)\n",
    "    return suicidal_thoughts_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Author's Age Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regex expressions\n",
    "age_matchers = [\n",
    "    {'matcher': re.compile(\"I('m| am) ([0-9][0-9]*)\", re.IGNORECASE), 'group': 2},\n",
    "    {'matcher': re.compile(\"I('m| am) in my ([0-9][0-9]*)\", re.IGNORECASE), 'group': 2},\n",
    "    {'matcher': re.compile(\"([0-9][0-9]*) years old\", re.IGNORECASE), 'group': 1},\n",
    "    {'matcher': re.compile(\"I('m| am) now ([0-9][0-9]*)\", re.IGNORECASE), 'group': 2},\n",
    "    {'matcher': re.compile(\"I('m| am) now at ([0-9][0-9]*)\", re.IGNORECASE), 'group': 2},\n",
    "    {'matcher': re.compile(\"([0-9][0-9]*)(f\\b|m\\b|f$|m$)\", re.IGNORECASE), 'group': 1},\n",
    "    {'matcher': re.compile(\"([0-9][0-9]*) (f\\b|m\\b|f$|m$)\", re.IGNORECASE), 'group': 1},\n",
    "    {'matcher': re.compile(\"([0-9][0-9]*)\\((f|m)\\)\", re.IGNORECASE), 'group': 1},\n",
    "    {'matcher': re.compile(\"([0-9][0-9]*) \\((f|m)\\)\", re.IGNORECASE), 'group': 1}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find age in text or return 0 if no age information\n",
    "def find_age(text):\n",
    "    for matcher in age_matchers:\n",
    "        if (r := matcher['matcher'].search(text)):\n",
    "            return int(r.group(matcher['group']))\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_authors_age_in_posts(idx):\n",
    "    age_idx = copy.deepcopy(idx)\n",
    "    def process_entry(author, text):\n",
    "        age = find_age(text)\n",
    "        age_idx[author]['age'] = age\n",
    "\n",
    "    for author, text in posts_and_commnets:\n",
    "        process_entry(author, text)\n",
    "    return age_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Migraine Triggers Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To this once\n",
    "# ! python -m spacy download en_core_web_sm\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "migraine_triggers = {\n",
    "    'alcohol',\n",
    "    'anxiety',\n",
    "    'caffeine',\n",
    "    'cheese',\n",
    "    'chocolate',\n",
    "    'coffee',\n",
    "    'dehydration',\n",
    "    'exercise',\n",
    "    'foods',\n",
    "    'heat',\n",
    "    'hormones',\n",
    "    'light',\n",
    "    'lights',\n",
    "    'medication',\n",
    "    'meds',\n",
    "    'nausea',\n",
    "    'pain',\n",
    "    'pressure',\n",
    "    'sleep',\n",
    "    'stress',\n",
    "    'sugar',\n",
    "    'tension',\n",
    "    'water',\n",
    "    'weather',\n",
    "    'wine'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_triggers_in_posts(nlp):\n",
    "    def process(idx):\n",
    "        trigger_idx = copy.deepcopy(idx)\n",
    "        pattern = re.compile('(trigger|triggers)', re.IGNORECASE)\n",
    "\n",
    "        def normalize_triggers(word):\n",
    "            if word == 'pressure':\n",
    "                return 'barometric pressure'\n",
    "            if word == 'water':\n",
    "                return 'dehydration'\n",
    "            if word == 'meds':\n",
    "                return 'medication'\n",
    "            return word\n",
    "\n",
    "        def find_triggers_in_text(text):\n",
    "            triggers = []\n",
    "            doc = nlp(text)\n",
    "            dep_type = None\n",
    "            for token in doc:\n",
    "                if (token.dep_ == 'nsubj' or token.dep_ == 'dobj' or token.dep_ == 'pobj') \\\n",
    "                    and pattern.search(token.text):\n",
    "                    dep_type = token.dep_\n",
    "                if token.pos_ == 'NOUN' and token.dep_ != dep_type and (token.dep_ == 'punc' or token.dep_ == 'dobj' or token.dep_ == 'conj'):\n",
    "                    if token.text in migraine_triggers:\n",
    "                        triggers.append(\n",
    "                            normalize_triggers(token.text)\n",
    "                        )\n",
    "            return triggers\n",
    "\n",
    "        def process_entry(author, text):\n",
    "            triggers = []\n",
    "            if pattern.search(text) is None:\n",
    "                trigger_idx[author]['triggers'] = triggers\n",
    "                return\n",
    "            for sentence in sentences_with_triggers(text):\n",
    "                triggers.extend(find_triggers_in_text(sentence))\n",
    "            trigger_idx[author]['triggers'] = triggers\n",
    "\n",
    "        def sentences_with_triggers(text):\n",
    "            doc = nlp(text)\n",
    "            sentences = [str(sent) for sent in doc.sents if pattern.search(str(sent))]\n",
    "            return sentences\n",
    "\n",
    "        for author, text in posts_and_commnets:\n",
    "            process_entry(author, text)\n",
    "        return trigger_idx\n",
    "    return process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "identify_authors_triggers_in_posts = find_triggers_in_posts(nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Author's with Aura Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_aura_matchers = [\n",
    "    re.compile('(i|my).*(aura|auras)', re.IGNORECASE),\n",
    "    re.compile('(with|first).*(aura|auras)', re.IGNORECASE),\n",
    "    re.compile('(aura|auras).*(me)', re.IGNORECASE)\n",
    "]\n",
    "\n",
    "negative_aura_matchers = [\n",
    "    re.compile('(i|my).*(\\snot\\s|without).*(aura|auras)', re.IGNORECASE),\n",
    "    re.compile(\"(i|my).*(don't|w/o).*(aura|auras)\", re.IGNORECASE)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_for_auras(text):\n",
    "    return any([matcher.search(text) for matcher in positive_aura_matchers]) \\\n",
    "        and not any([matcher.search(text) for matcher in negative_aura_matchers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_authors_aura_in_posts(idx):\n",
    "    aura_idx = copy.deepcopy(idx)\n",
    "    def process_entry(author, text):\n",
    "        aura_idx[author]['aura'] = str(bool(search_for_auras(text))).lower()\n",
    "\n",
    "    for author, text in posts_and_commnets:\n",
    "        process_entry(author, text)\n",
    "    return aura_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Author's with ADHD Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_adhd_matchers = [\n",
    "    re.compile('(i|my).*(adhd)', re.IGNORECASE),\n",
    "    re.compile('(take|treat|treating|diagnosed|prescription).*(adhd)', re.IGNORECASE),\n",
    "    re.compile('(adhd).*(here)', re.IGNORECASE)\n",
    "]\n",
    "\n",
    "negative_adhd_matchers = [\n",
    "    re.compile('(i|my).*(\\snot\\s|without).*(aura|auras)', re.IGNORECASE),\n",
    "    re.compile(\"(i|my).*(don't|\\sno\\s).*(aura|auras)\", re.IGNORECASE)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_for_adhd(text):\n",
    "    return any([matcher.search(text) for matcher in positive_adhd_matchers]) \\\n",
    "        and not any([matcher.search(text) for matcher in negative_adhd_matchers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_authors_adhd_in_posts(idx):\n",
    "    adhd_idx = copy.deepcopy(idx)\n",
    "    def process_entry(author, text):\n",
    "        adhd_idx[author]['adhd'] = str(bool(search_for_adhd(text))).lower()\n",
    "\n",
    "    for author, text in posts_and_commnets:\n",
    "        process_entry(author, text)\n",
    "    return adhd_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Author Reverse Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature functions\n",
    "feature_discovery = [\n",
    "    identify_gender_in_posts,\n",
    "    identify_medicine_in_posts,\n",
    "    identify_suicidal_thoughts_in_posts,\n",
    "    identify_authors_age_in_posts,\n",
    "    identify_authors_triggers_in_posts,\n",
    "    identify_authors_aura_in_posts,\n",
    "    identify_authors_adhd_in_posts\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3505567/642456063.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_discovery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mauthor_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauthor_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_3505567/2641560964.py\u001b[0m in \u001b[0;36mrun_pipe\u001b[0;34m(input)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfunctions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrun_pipe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3505567/2032028081.py\u001b[0m in \u001b[0;36midentify_medicine_in_posts\u001b[0;34m(idx)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mauthor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mposts_and_commnets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mprocess_entry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauthor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmedicine_idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3505567/2032028081.py\u001b[0m in \u001b[0;36mprocess_entry\u001b[0;34m(author, text)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmedicine_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprocess_entry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauthor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mmed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdosage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_medicine_dosage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mmedicine_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mauthor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'medicine'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mmedicine_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mauthor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dosage'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdosage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3505567/3424461408.py\u001b[0m in \u001b[0;36mprocess_medicine_dosage\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0mdosage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_dosage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreg_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdosage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                     \u001b[0mmed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_medicine_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mmed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                         return (\n",
      "\u001b[0;32m/tmp/ipykernel_3505567/3424461408.py\u001b[0m in \u001b[0;36mfind_medicine_name\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mmeds_matched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdrug\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdrug_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIGNORECASE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0mmeds_matched\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmeds_matched\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.0/lib/python3.9/re.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(pattern, string, flags)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \"\"\"Scan through string looking for a match to the pattern, returning\n\u001b[1;32m    200\u001b[0m     a Match object, or None if no match was found.\"\"\"\n\u001b[0;32m--> 201\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pipeline = pipe(feature_discovery)\n",
    "author_index = pipeline(author_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Features Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features like suicidal, ADHD, aura are set for all of the authors\n",
    "# so we ignore those \n",
    "def has_features(entry):\n",
    "    if entry['age'] == 0 and \\\n",
    "       len(entry['triggers']) == 0 and \\\n",
    "       entry['medicine'] == 'unknown' and \\\n",
    "       entry['gender'] == 'unknown':\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def has_all_features(entry):\n",
    "    if entry['age'] != 0 and \\\n",
    "       len(entry['triggers']) != 0 and \\\n",
    "       entry['medicine'] != 'unknown' and \\\n",
    "       entry['gender'] != 'unknown':\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authors with at least one feature: 4298\n",
      "Authors with all features: 3\n"
     ]
    }
   ],
   "source": [
    "# Count at least one and all features\n",
    "total_at_least_one = 0\n",
    "total_all = 0\n",
    "\n",
    "for author, entry in author_index.items():\n",
    "    if has_features(entry):\n",
    "        total_at_least_one += 1\n",
    "    if has_all_features(entry):\n",
    "        total_all += 1\n",
    "\n",
    "print(f'Authors with at least one feature: {total_at_least_one}')\n",
    "print(f'Authors with all features: {total_all}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "for _, entry in author_index.items():\n",
    "    entry['id'] = uuid.uuid4()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4298"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list = [entry for _, entry in author_index.items() if has_features(entry)]\n",
    "output_df = pd.DataFrame(data=data_list)\n",
    "len(output_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dataset_filename = 'migraine_all_group11.csv'\n",
    "output_df.to_csv(f'data/{output_dataset_filename}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "043ded0200596b90969cdaf78db8cc3255494a426d99ef977fa69e36f146e9e2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit ('migraine-data-reddit-WM5Df_6q-py3.9': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
