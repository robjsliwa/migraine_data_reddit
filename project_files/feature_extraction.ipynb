{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "\n",
    "The purpose of this notebook is to show how and the process of extracting each feature form texts of posts in Reddis and migraine.com\n",
    "\n",
    "Based on the work done for the [project proposal](./group_11_proposal.ipynb) we identified following features to extract:\n",
    "\n",
    "- Age\n",
    "- Gender\n",
    "- Medicine use and dosage\n",
    "- Suicidal thoughts\n",
    "- Migraine triggers\n",
    "- Presence of aura\n",
    "- Trouble with sleeping\n",
    "- ADHD\n",
    "\n",
    "In the rest of this notebook we show the process of getting each feature out and constructing the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import unittest\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddis_data_filename = 'reddis_migraine_posts.csv'\n",
    "migraine_dot_com = 'migraine.com.csv'\n",
    "csv_files = [reddis_data_filename, migraine_dot_com]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_reddis_data(files):\n",
    "    dfs = []\n",
    "    for file in files:\n",
    "        dfs.append(pd.read_csv(f'data/{file}', header=0))\n",
    "        df = pd.concat(dfs)\n",
    "        df = df.dropna(subset=['Text'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_and_commnets = read_reddis_data(csv_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Parent</th>\n",
       "      <th>Author</th>\n",
       "      <th>Text</th>\n",
       "      <th>Title</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Webpage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P</td>\n",
       "      <td>q1pdf8</td>\n",
       "      <td>Conscious_Escape_408</td>\n",
       "      <td>I've been awake the entire night with the wors...</td>\n",
       "      <td>Worst I've ever had/calling in sick</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P</td>\n",
       "      <td>q1p2lt</td>\n",
       "      <td>Sia-King</td>\n",
       "      <td>Hey y’all, I got a referral for a neurologist ...</td>\n",
       "      <td>What preventative to trial next? (Asthmatic &amp;a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P</td>\n",
       "      <td>q1otox</td>\n",
       "      <td>netluv</td>\n",
       "      <td>It’s day two night two of a migraine. I’ve max...</td>\n",
       "      <td>Pain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P</td>\n",
       "      <td>q1odf7</td>\n",
       "      <td>Dazee80</td>\n",
       "      <td>I am in a fucked position. I have had migraine...</td>\n",
       "      <td>Pain vs Relationship</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>P</td>\n",
       "      <td>q1kv1i</td>\n",
       "      <td>doitforthepizza</td>\n",
       "      <td>Hi everyone, I'm new here (44f). First I'll sa...</td>\n",
       "      <td>New to this and wondering if others experience...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Type  Parent                Author  \\\n",
       "0    P  q1pdf8  Conscious_Escape_408   \n",
       "1    P  q1p2lt              Sia-King   \n",
       "2    P  q1otox                netluv   \n",
       "3    P  q1odf7               Dazee80   \n",
       "5    P  q1kv1i       doitforthepizza   \n",
       "\n",
       "                                                Text  \\\n",
       "0  I've been awake the entire night with the wors...   \n",
       "1  Hey y’all, I got a referral for a neurologist ...   \n",
       "2  It’s day two night two of a migraine. I’ve max...   \n",
       "3  I am in a fucked position. I have had migraine...   \n",
       "5  Hi everyone, I'm new here (44f). First I'll sa...   \n",
       "\n",
       "                                               Title Tags Webpage  \n",
       "0                Worst I've ever had/calling in sick  NaN     NaN  \n",
       "1  What preventative to trial next? (Asthmatic &a...  NaN     NaN  \n",
       "2                                               Pain  NaN     NaN  \n",
       "3                               Pain vs Relationship  NaN     NaN  \n",
       "5  New to this and wondering if others experience...  NaN     NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_and_commnets[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For most of our processing we will need Author and Text columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_and_commnets = list(posts_and_commnets[['Author', 'Text']].to_records(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Conscious_Escape_408', \"I've been awake the entire night with the worst migraine I have ever had. Im a long time sufferer but this one is different. My thinking is more impaired than usual and my blood pressure is 150/111. I need to call out sick from work but I'm so afraid of getting in trouble. I'm afraid to go to hospital emergency room with the number of COVID cases in my area. I don't know what to do.\"),\n",
       " ('Sia-King', 'Hey y’all, I got a referral for a neurologist and while I’m waiting on it, I’ve decided to trial another preventative. I’ve tried Topomax (was on it 2 weeks, couldn’t handle the side effects), currently on Sandomigran (been on it for 19 months, stopped working 9 months in but I continued w it because I didn’t want to accept it wasn’t working 😭 when it did work, it was bloody amazing. While I can increase the dosage for effectiveness, I can barely handle the fatigue it gives). \\n\\nI have asthma and take venlafaxine for depression &amp; anxiety btw. My GP said this means my options are more limited for preventatives. \\n\\nAny suggestions for preventatives?? I’ll check if my GP is happy to prescribe. TIA :))')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_and_commnets[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction Approach\n",
    "\n",
    "Different features needed somewhat different approach to retrieving them from the posts and comments.  However, there is general workflow that we used for working on all of the features.  \n",
    "\n",
    "The nature of the data is that authors write in multiple posts and comments.  The main goal is to scan through these posts and identify features for each author.  Different features can come from author's different posts.  For example, in one post author can be speaking about something that identifies their gender and in another post about something that identifies their age.\n",
    "\n",
    "To capture all the features we create index where author is the key and value is a dictionary of the features.\n",
    "\n",
    "Workflow:\n",
    "\n",
    "- Find sentences that describe feature we are looking for.  We do this by first identifying some keyword and filtering posts by that keyword and than taking random sample from that list.\n",
    "- Once the list of sample sentences that represent feature is created, we build set of regex expression to identify all of the language patterns that the feature can be expressed with.\n",
    "- With both sample sentences and regex expressions we build function that can identify the feature given text.  To ensure that the function works correctly we create unittest and use sample sentences as input for the unittest.  This saves us time from debugging later on large dataset.\n",
    "- Finally, we run feature extracting function again entire dataset and update author index with found features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up Author Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "author_index = defaultdict(dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine Number of Unique Authors\n",
    "\n",
    "Checking number of unique authors in the dataset. This will be maximum possible number of entries for our resulting dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total posts and comments: 410708\n",
      "Unique authors: 46918\n"
     ]
    }
   ],
   "source": [
    "from itertools import groupby\n",
    "\n",
    "\n",
    "print(f'Total posts and comments: {len(posts_and_commnets)}')\n",
    "unique_authors = [x[0] for x in posts_and_commnets]\n",
    "print(f'Unique authors: {len(set(unique_authors))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature - Discover Gender\n",
    "\n",
    "For Reddis authors we must extract information on author's gender from the posts themselves as userids are auto generated by Reddis so there is very little chance that someone would change it to their names.\n",
    "\n",
    "In order to figure out how to do it we looked through posts and looked for examples of how people either identify themselves or if they say something that would help us to identify their gender, for example, \"Me and my husband.\"\n",
    "\n",
    "We found following sentences that we used to retrieve regex patterns from:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_male_sentences = [\n",
    "    \"I am married and my Wife and I....\",\n",
    "    \"Me and my girlfriend went somewhere\",\n",
    "    \"Hello, me 44m and have migraines\",\n",
    "    \"Hello, me 44(m) and have migraines\",\n",
    "    \"Hello, me 44 (M) and have migraines\",\n",
    "    \"Hello, me 44 male and have migraines\",\n",
    "    \"Hello, I am male 44 and have migraines\"\n",
    "]\n",
    "\n",
    "sample_female_sentences = [\n",
    "    \"Me and my husband have a car.\",\n",
    "    \"Something I am currently pregnant and so on\",\n",
    "    \"Something I am pregnant and so on\",\n",
    "    \"Something I'm pregnant and so on\",\n",
    "    \"I have had menstruation related migraine\",\n",
    "    \"Me and my boyfriend went somewhere\",\n",
    "    \"Hello, me 44f and have migraines\",\n",
    "    \"Hello, me 44(f) and have migraines\",\n",
    "    \"Hello, me 44 (F) and have migraines\",\n",
    "    \"Hello, me 44 female and have migraines\",\n",
    "    \"Hello, I am female 44 and have migraines\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex patterns\n",
    "male_matchers = [\n",
    "    re.compile('my\\s+wife', re.IGNORECASE),\n",
    "    re.compile('my\\s.*girlfriend', re.IGNORECASE),\n",
    "    re.compile('\\s[0-9][0-9](m\\s|\\(m\\)|\\s\\(m\\))', re.IGNORECASE),\n",
    "    re.compile('\\s[0-9][0-9].*male', re.IGNORECASE),\n",
    "    re.compile('male.*[0-9][0-9]', re.IGNORECASE)\n",
    "]\n",
    "\n",
    "female_matchers = [\n",
    "    re.compile('my\\s+husband', re.IGNORECASE),\n",
    "    re.compile('I( am|\\'m)\\s.*pregnant', re.IGNORECASE),\n",
    "    re.compile('I\\s.*menstruation', re.IGNORECASE),\n",
    "    re.compile('my\\s.*boyfriend', re.IGNORECASE),\n",
    "    re.compile('\\s[0-9][0-9](f|\\(f\\)|\\s\\(f\\))', re.IGNORECASE),\n",
    "    re.compile('\\s[0-9][0-9].*female', re.IGNORECASE),\n",
    "    re.compile('female.*[0-9][0-9]', re.IGNORECASE)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender discovery functions\n",
    "def discover_gender(matchers):\n",
    "    def find_in_text(text):\n",
    "        return any([\n",
    "            matcher.search(text) for matcher in matchers\n",
    "        ])\n",
    "    return find_in_text\n",
    "\n",
    "find_females = discover_gender(female_matchers)\n",
    "find_males = discover_gender(male_matchers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_female_matchers (__main__.TestGenderDiscovery) ... ok\n",
      "test_male_matchers (__main__.TestGenderDiscovery) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.001s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "# Unit tests\n",
    "class TestGenderDiscovery(unittest.TestCase):\n",
    "    def test_male_matchers(self):\n",
    "        self.assertTrue(all([find_males(text) for text in sample_male_sentences]))\n",
    "        self.assertFalse(all([find_males(text) for text in sample_female_sentences]))\n",
    "\n",
    "    def test_female_matchers(self):\n",
    "        self.assertTrue(all([find_females(text) for text in sample_female_sentences]))\n",
    "        self.assertFalse(all([find_females(text) for text in sample_male_sentences]))\n",
    "\n",
    "res = unittest.main(argv=[''], verbosity=3, exit=False)\n",
    "assert len(res.result.failures) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_gender(text):\n",
    "    if find_males(text):\n",
    "        return 'male'\n",
    "    elif find_females(text):\n",
    "        return 'female'\n",
    "    return 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_gender_in_posts(idx):\n",
    "    gender_idx = copy.deepcopy(idx)\n",
    "    def process_entry(author, text):\n",
    "        gender_idx[author]['gender'] = identify_gender(text)\n",
    "\n",
    "    for author, text in posts_and_commnets:\n",
    "        process_entry(author, text)\n",
    "    return gender_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46918"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_index = identify_gender_in_posts(author_index)\n",
    "len(author_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count how many authors were identified as male or female or unknown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male: 780, female: 826, unknown: 45312\n"
     ]
    }
   ],
   "source": [
    "count_m = 0\n",
    "count_f = 0\n",
    "count_u = 0\n",
    "\n",
    "for _, v in author_index.items():\n",
    "    if v['gender'] == 'male':\n",
    "        count_m += 1\n",
    "    if v['gender'] == 'female':\n",
    "        count_f += 1\n",
    "    if v['gender'] == 'unknown':\n",
    "        count_u += 1\n",
    "\n",
    "print(f'male: {count_m}, female: {count_f}, unknown: {count_u}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature - Drug Information\n",
    "\n",
    "This section describes process of identifying medicine and dosage used by authors.\n",
    "\n",
    "We first started by searching for most common drugs used for migraine.  We found that information on this [website](https://www.healthgrades.com/right-care/migraine-and-headache/12-drugs-commonly-prescribed-for-migraine)\n",
    "\n",
    "## Common Migraine Drugs\n",
    "\n",
    "- **Amitriptyline (Elavil)** is an antidepressant. The dosing ranges from once a day up to four times a day. It belongs to a group of antidepressants called tricyclics. Drowsiness and sleepiness are very common with this group, so your doctor may recommend taking it at bedtime.\n",
    "- **Divalproex sodium extended-release (Depakote ER)** is an anticonvulsant. You take the extended-release tablet once a day. Taking it with food can help prevent stomach upset.\n",
    "- **Eletriptan (Relpax)** is a triptan. It is a tablet you take at the onset of your migraine symptoms. For triptans, your doctor will tell you how many tablets you can take in a 24 hour period.\n",
    "- **Metoprolol (Lopressor, Toprol XL)** is a beta blocker. It comes in both an immediate-release and an extended-release form.\n",
    "- **Propranolol extended-release (Inderal, Inderal LA, Inderal XL)** is another beta blocker. It comes in several forms, each with their own dosing. Talk with your doctor or pharmacist about how to take your medicine.\n",
    "- **Rizatriptan (Maxalt)** is a triptan you use at the onset of symptoms. It comes as a tablet and a disintegrating tablet, which melts in your mouth without water.\n",
    "- **Sumatriptan (Imitrex)** is another triptan. It comes in several forms, including a tablet, injection, and nasal spray.\n",
    "- **Topiramate (Topamax, Trokendi XR)** is an anticonvulsant. It comes in a regular-release tablet and an extended-release capsule. You can take either kind with or without food.\n",
    "- **Venlafaxine (Effexor, Effexor XR)** is an antidepressant. You take both the tablet and the extended-release capsule with food. Stomach upset, headache, and appetite loss are common side effects.\n",
    "- **Zolmitriptan (Zomig)** is another triptan. It comes as a tablet, disintegrating table, and nasal spray.\n",
    "- **OnabotulinumtoxinA (Botox)** is a botulinum toxin that, when injected into areas of the face and scalp, can prevent the brain's pain response from activating. This stops migraine attacks before they occur.\n",
    "- **Erenumab (Aimovig)** is a CGRP blocker. It's given by self-injection once a month.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we created a list of drugs and added some additional drugs we saw in Reddit posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_list = [\n",
    "    'Amitriptyline',\n",
    "    'Elavil',\n",
    "    'Divalproex',\n",
    "    'Depakote',\n",
    "    'Eletriptan',\n",
    "    'Relpax',\n",
    "    'triptan',\n",
    "    'Metoprolol',\n",
    "    'Lopressor',\n",
    "    'Toprol',\n",
    "    'Propranolol',\n",
    "    'Inderal',\n",
    "    'beta blocker',\n",
    "    'Rizatriptan',\n",
    "    'Maxalt',\n",
    "    'Sumatriptan',\n",
    "    'Imitrex',\n",
    "    'Topiramate',\n",
    "    'Topamax',\n",
    "    'Trokendi',\n",
    "    'Venlafaxine',\n",
    "    'Effexor',\n",
    "    'Zolmitriptan',\n",
    "    'Zomig',\n",
    "    'OnabotulinumtoxinA',\n",
    "    'Botox',\n",
    "    'Erenumab',\n",
    "    'Aimovig',\n",
    "    'CGRP',\n",
    "    'Nurtec',  # found in the subreddit post\n",
    "    'Topomax',  # popular misspelling of Topamax,\n",
    "    'nortiptyline',  # found in the subreddit post\n",
    "    'metoclopramide',  # found in the subreddit post\n",
    "    'caffeine pill',  # found in the subreddit posts_and_comments\n",
    "    'naproxen',\n",
    "    'magnesium',\n",
    "    'Delta 8',\n",
    "    'Aimovig',\n",
    "    'sulfate',\n",
    "    'Xanax',\n",
    "    'amitryptiline',\n",
    "    'Amoxicillin'\n",
    "]\n",
    "\n",
    "# drug_list = set([s.lower() for s in drug_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Medicine Patterns\n",
    "\n",
    "Manually sampling above output we found following patterns to base our regex expressions on:\n",
    "\n",
    "- 75mg topamax daily\n",
    "- Recently been prescribed 25mg topiramate to take one a day before bed\n",
    "- I'm on 50mg and feel no effect at all\n",
    "- I'm on 50mg and dont feel completely wrecked the next day. But I also have a sleep disorder that benefits from amitriptyline making me tired at night\n",
    "- I’m currently on daily 40mg of Propranolol\n",
    "- my current amitryptiline dose (50mg)\n",
    "- prescribed me 50mg amitriptyline\n",
    "- I take 2 x 600 mg caps of magnesium\n",
    "- I take 10mg of edible Delta 8\n",
    "- I was on 10mg which worked great for 6 months\n",
    "- Now I take 30 mg\n",
    "- It's a combination of sumatriptan 85 mg and naproxen sodium 500 mg\n",
    "- I use 50 mg with a triptan\n",
    "- I currently take 75mg daily\n",
    "- I'm at 20mg 3x a day now\n",
    "- I started Aimovig in July 2018 at the 70mg dose\n",
    "- I take 50mg daily\n",
    "- She said 875mg of Amoxicillin\n",
    "- I take a total of 2400mg/day: 900mg/600mg/900mg.\n",
    "- it 80mg twice a day\n",
    "- Years ago i took 900mg three times a day\n",
    "- 300mg 3x a day\n",
    "- sulfate 325 mg twice daily\n",
    "- I took .5 mg of Xanax\n",
    "- my doc prescribed me 10mg of amitriptyline nightly\n",
    "- my dose is 2x 25mg\n",
    "- Topamax took about a month for me (at 50 mg)\n",
    "- Mine comes in 2.5mg.\n",
    "- but I take 250mg/day\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_drug_sentences = [\n",
    "    '75mg topamax daily',\n",
    "    'Recently been prescribed 25mg topiramate to take one a day before bed',\n",
    "    \"I'm on 50mg Topomax and feel no effect at all\",\n",
    "    \"I'm on 50mg Topomax and dont feel completely wrecked the next day. But I also have a sleep disorder that benefits from amitriptyline making me tired at night\",\n",
    "    'I’m currently on daily 40mg of Propranolol',\n",
    "    'my current amitryptiline dose (50mg)',\n",
    "    'prescribed me 50mg amitriptyline',\n",
    "    'I take 2 x 600 mg caps of magnesium',\n",
    "    'I take 10mg of edible Delta 8',\n",
    "    'I was on 10mg of Topomax which worked great for 6 months',\n",
    "    'Now I take 30 mg of Topomax',\n",
    "    'It\\'s a combination of sumatriptan 85 mg and naproxen sodium 500 mg',\n",
    "    'I use 50 mg with a triptan',\n",
    "    'I currently take Topomax 75mg daily',\n",
    "    'I\\'m on Topomax at 20mg 3x a day now',\n",
    "    'I started Aimovig in July 2018 at the 70mg dose',\n",
    "    'I take 50mg daily of Topomax',\n",
    "    'She said 875mg of Amoxicillin',\n",
    "    'I take Topomax a total of 2400mg/day: 900mg/600mg/900mg.',\n",
    "    'Topomax 80mg twice a day',\n",
    "    'Years ago i took Topomax 900mg three times a day',\n",
    "    'Topomax 300mg 3x a day',\n",
    "    'sulfate 325 mg twice daily',\n",
    "    'I took .5 mg of Xanax',\n",
    "    'my doc prescribed me 10mg of amitriptyline nightly',\n",
    "    'my dose of Aimovig is 2x 25mg',\n",
    "    'Topamax took about a month for me (at 50 mg)',\n",
    "    'Mine Topamax comes in 2.5mg.',\n",
    "    'but I take 250mg/day of Xanax'\n",
    "]\n",
    "\n",
    "invalid_drug_sentences = [\n",
    "    'I took .5 days of vaction',\n",
    "    'my doc prescribed me 10 days of rest',\n",
    "    'my car is 25kg heavier',\n",
    "    '50 mg of stuff',\n",
    "    'Mine Topamax comes in 2-5 weeks.'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of regex patterns is a bit more complex than previous one as we needed to store regex group indexes for dosage and quantity as they can appear at different positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regex patterns\n",
    "drug_matchers = [\n",
    "    {\n",
    "        'regex': re.compile('([0-9]x).*([0-9]+\\.?[0-9]+mg|[0-9]+\\.?[0-9]+\\smg|\\.?[0-9]+mg|\\.?[0-9]+\\smg)', flags=re.IGNORECASE),\n",
    "        'dosage_group': 2,\n",
    "        'qty_group': 1\n",
    "    },\n",
    "    {\n",
    "        'regex': re.compile('([0-9]+\\.?[0-9]+mg|[0-9]+\\.?[0-9]+\\smg|\\.?[0-9]+mg|\\.?[0-9]+\\smg).*([0-9]x)', flags=re.IGNORECASE),\n",
    "        'dosage_group': 1,\n",
    "        'qty_group': 2\n",
    "    },\n",
    "    {\n",
    "        'regex': re.compile('([0-9]+\\.?[0-9]+mg|[0-9]+\\.?[0-9]+\\smg|\\.?[0-9]+mg|\\.?[0-9]+\\smg).*(three times a day|four times a day|twice a day|one a day|twice daily)', flags=re.IGNORECASE),\n",
    "        'dosage_group': 1,\n",
    "        'qty_group': 2\n",
    "    },\n",
    "    {\n",
    "        'regex': re.compile('([0-9]+mg|[0-9]+\\smg).*(nightly|daily|dose|day)', flags=re.IGNORECASE),\n",
    "        'dosage_group': 1,\n",
    "        'qty_group': 2\n",
    "    },\n",
    "    {\n",
    "        'regex': re.compile('([0-9]+\\.?[0-9]+mg|[0-9]+\\.?[0-9]+\\smg|\\.?[0-9]+mg|\\.?[0-9]+\\smg)', flags=re.IGNORECASE),\n",
    "        'dosage_group': 1,\n",
    "        'qty_group': -1\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Medicine discovery functions\n",
    "def normalize_qty(qty_text):\n",
    "    if qty_text == 'daily' or qty_text == 'dose' or qty_text == 'day' or qty_text == 'one a day' or qty_text == '1x':\n",
    "        return '1x'\n",
    "\n",
    "    if qty_text == 'twice daily' or qty_text == 'twice a day':\n",
    "        return '2x'\n",
    "\n",
    "    if qty_text == 'three times a day':\n",
    "        return '3x'\n",
    "\n",
    "    return qty_text\n",
    "\n",
    "def find_medicine_name(text):\n",
    "    meds_matched = []\n",
    "    for drug in drug_list:\n",
    "        if re.search(drug, text, re.IGNORECASE):\n",
    "            meds_matched.append(drug)\n",
    "    return meds_matched\n",
    "\n",
    "def find_dosage(reg_res, matcher):\n",
    "    if matcher['qty_group'] == -1:\n",
    "        qty = '1x'\n",
    "    else:\n",
    "        qty = normalize_qty(reg_res.group(matcher['qty_group']))\n",
    "    return reg_res.group(matcher['dosage_group']), qty\n",
    "\n",
    "def discover_medicine_dosage(matchers):\n",
    "    def process_medicine_dosage(text):\n",
    "        for matcher in matchers:\n",
    "            if (reg_res := matcher['regex'].search(text)):\n",
    "                dosage, qty = find_dosage(reg_res, matcher)\n",
    "                if dosage:\n",
    "                    med = find_medicine_name(text)\n",
    "                    if med:\n",
    "                        return (\n",
    "                            med[0],\n",
    "                            dosage,\n",
    "                            qty\n",
    "                        )\n",
    "\n",
    "        return 'unknown', 'unknown', 'unknown'\n",
    "    return process_medicine_dosage\n",
    "\n",
    "find_medicine_dosage = discover_medicine_dosage(drug_matchers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_female_matchers (__main__.TestGenderDiscovery) ... ok\n",
      "test_male_matchers (__main__.TestGenderDiscovery) ... ok\n",
      "test_dosage_matchers (__main__.TestMedicineDosageDiscovery) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.007s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "# Unit tests\n",
    "def is_dosage_found(result):\n",
    "    med, dosage, qty = result\n",
    "    if med != 'unknown' and dosage != 'unknown' and qty != 'unknown':\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "class TestMedicineDosageDiscovery(unittest.TestCase):\n",
    "    def test_dosage_matchers(self):\n",
    "        self.assertTrue(all([is_dosage_found(find_medicine_dosage(text)) for text in sample_drug_sentences]))\n",
    "        self.assertFalse(all([is_dosage_found(find_medicine_dosage(text)) for text in invalid_drug_sentences]))\n",
    "\n",
    "res = unittest.main(argv=[''], verbosity=3, exit=False)\n",
    "assert len(res.result.failures) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run `find_medicine_dosage` function to find all entries in posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_medicine_in_posts(idx):\n",
    "    medicine_idx = copy.deepcopy(idx)\n",
    "    def process_entry(author, text):\n",
    "        med, dosage, qty = find_medicine_dosage(text)\n",
    "        medicine_idx[author]['medicine'] = med\n",
    "        medicine_idx[author]['dosage'] = dosage\n",
    "        medicine_idx[author]['qty'] = qty\n",
    "\n",
    "    for author, text in posts_and_commnets:\n",
    "        process_entry(author, text)\n",
    "    return medicine_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46918"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_index = identify_medicine_in_posts(author_index)\n",
    "len(author_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entries with medicine dosage: 1387\n"
     ]
    }
   ],
   "source": [
    "count_medicine = 0\n",
    "\n",
    "for _, v in author_index.items():\n",
    "    if v['medicine'] != 'unknown':\n",
    "        count_medicine += 1\n",
    "\n",
    "print(f'entries with medicine dosage: {count_medicine}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature - Suicidal Thoughts\n",
    "\n",
    "This section attempts to identify all of the authors that had suicidal thoughts.\n",
    "\n",
    "Following is the list of sample sentences talking about suicide and they will serve as a test sentences and patterns for creating regex expression to retrieve information on suicidal thoughts.\n",
    "\n",
    "Regex expression are divided into positive and negative.\n",
    "With these sentences it is important not to pick up negative sentences that would mean the exact opposite to what we are trying to detect.\n",
    "\n",
    "For example, we want to capture `I have suicidal thoughts` BUT we don't want to capture `I don't have suicidal thoughts`.  For this reason we will create regex set for capturing the negative sentences as well so that we can eliminate them from consideration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "suicide_sample_sentences = [\n",
    "    'Had suicidal thoughts',\n",
    "    'made me think a lot about suicide',\n",
    "    'I still thought about suicide',\n",
    "    'Suicide ideation',\n",
    "    'suicidal ideations',\n",
    "    'The “intrusive thoughts” and experiencing life far away'\n",
    "    'I had felt suicidal',\n",
    "    'feeling sad/suicidal',\n",
    "    'it made me wildly suicidal',\n",
    "    'I have been extremely suicidal',\n",
    "    'i also have been extremely suicidal',\n",
    "    'and then attempted suicide to stop the pain',\n",
    "    'my near suicide attempt',\n",
    "    'Depression and suicide thoughts are unbearable for me',\n",
    "    'I was having suicidal thoughts',\n",
    "    'I self harm and have suicidal thoughts',\n",
    "    'just made me suicidal',\n",
    "    'I was so suicidal',\n",
    "    'made me legitimately suicidal',\n",
    "    'Had suicidal thoughts',\n",
    "    'I still thought about suicide',\n",
    "    'made me think a lot about suicide'\n",
    "]\n",
    "\n",
    "neg_suicide_sample_sentences = [\n",
    "    'I am not suicidal',\n",
    "    'I have never been suicidal'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regex expressions\n",
    "positive_suicide_matchers = [\n",
    "    re.compile('(am|have|had|felt|having|me|was|been|think|about|feeling).*(suicidal|suicide)', re.IGNORECASE),\n",
    "    re.compile('(my near|made me|have been|thought about|).*(suicidal|suicide)', re.IGNORECASE)\n",
    "]\n",
    "\n",
    "negative_suicide_matchers = [\n",
    "    re.compile('(am|have|had|felt|having|me|was|been|think|about|feeling) (not|never).*(suicidal|suicide)', re.IGNORECASE),\n",
    "    re.compile('(my near|made me|have been|thought about|) (not|never).*(suicidal|suicide)', re.IGNORECASE)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_for_suicide(text):\n",
    "    return any([matcher.search(text) for matcher in positive_suicide_matchers]) \\\n",
    "        and not any([matcher.search(text) for matcher in negative_suicide_matchers])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_female_matchers (__main__.TestGenderDiscovery) ... ok\n",
      "test_male_matchers (__main__.TestGenderDiscovery) ... ok\n",
      "test_dosage_matchers (__main__.TestMedicineDosageDiscovery) ... ok\n",
      "test_suicidal_matchers (__main__.TestSuicidalThoughtsDiscovery) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.007s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "# Unit tests\n",
    "class TestSuicidalThoughtsDiscovery(unittest.TestCase):\n",
    "    def test_suicidal_matchers(self):\n",
    "        self.assertTrue(all([search_for_suicide(text) for text in suicide_sample_sentences]))\n",
    "        self.assertFalse(all([search_for_suicide(text) for text in neg_suicide_sample_sentences]))\n",
    "\n",
    "res = unittest.main(argv=[''], verbosity=3, exit=False)\n",
    "assert len(res.result.failures) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_suicidal_thoughts_in_posts(idx):\n",
    "    suicidal_thoughts_idx = copy.deepcopy(idx)\n",
    "    def process_entry(author, text):\n",
    "        if search_for_suicide(text):\n",
    "            suicidal_thoughts_idx[author]['suicidal'] = 'yes'\n",
    "        else:\n",
    "            suicidal_thoughts_idx[author]['suicidal'] = 'no'\n",
    "\n",
    "    for author, text in posts_and_commnets:\n",
    "        process_entry(author, text)\n",
    "    return suicidal_thoughts_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46918"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_index = identify_suicidal_thoughts_in_posts(author_index)\n",
    "len(author_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authors with with suicidal thoughts: 155\n"
     ]
    }
   ],
   "source": [
    "total_suicidal = 0\n",
    "\n",
    "for _, v in author_index.items():\n",
    "    if v['suicidal'] == 'yes':\n",
    "        total_suicidal += 1\n",
    "\n",
    "print(f'Authors with with suicidal thoughts: {total_suicidal}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature - Author's Age\n",
    "\n",
    "This section discovers author's age from the posts.  This is similar pattern of finding sample sentences and creating regex expressions based on those samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_sample_sentences = [\n",
    "    \"I'm 26\",\n",
    "    \"I'm 9\",\n",
    "    \"I am 26\",\n",
    "    \"I'm in my 40's\",\n",
    "    \"45 years old\",\n",
    "    \"I am 20 (F)\",\n",
    "    \"I am 28M\",\n",
    "    \"I am now at 58\",\n",
    "    \"I'm now 20\",\n",
    "    \"40f\"\n",
    "]\n",
    "\n",
    "no_age_sentences = [\n",
    "    \"I'm good\",\n",
    "    \"I am bad\",\n",
    "    \"I'm in my house\",\n",
    "    \"years old\",\n",
    "    \"I am (F)\",\n",
    "    \"I am M\",\n",
    "    \"I am now at the shop\",\n",
    "    \"I'm now better\",\n",
    "    \"is f\",\n",
    "    \"I am on vyepti (every 3 months) along with\",\n",
    "    \"a good 30-45 minutes\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regex expressions\n",
    "age_matchers = [\n",
    "    {'matcher': re.compile(\"I('m| am) ([0-9][0-9]*)\", re.IGNORECASE), 'group': 2},\n",
    "    {'matcher': re.compile(\"I('m| am) in my ([0-9][0-9]*)\", re.IGNORECASE), 'group': 2},\n",
    "    {'matcher': re.compile(\"([0-9][0-9]*) years old\", re.IGNORECASE), 'group': 1},\n",
    "    {'matcher': re.compile(\"I('m| am) now ([0-9][0-9]*)\", re.IGNORECASE), 'group': 2},\n",
    "    {'matcher': re.compile(\"I('m| am) now at ([0-9][0-9]*)\", re.IGNORECASE), 'group': 2},\n",
    "    {'matcher': re.compile(\"([0-9][0-9]*)(f\\b|m\\b|f$|m$)\", re.IGNORECASE), 'group': 1},\n",
    "    {'matcher': re.compile(\"([0-9][0-9]*) (f\\b|m\\b|f$|m$)\", re.IGNORECASE), 'group': 1},\n",
    "    {'matcher': re.compile(\"([0-9][0-9]*)\\((f|m)\\)\", re.IGNORECASE), 'group': 1},\n",
    "    {'matcher': re.compile(\"([0-9][0-9]*) \\((f|m)\\)\", re.IGNORECASE), 'group': 1}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find age in text or return 0 if no age information\n",
    "def find_age(text):\n",
    "    for matcher in age_matchers:\n",
    "        if (r := matcher['matcher'].search(text)):\n",
    "            return int(r.group(matcher['group']))\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_age_matchers (__main__.TestAgeDiscovery) ... ok\n",
      "test_female_matchers (__main__.TestGenderDiscovery) ... ok\n",
      "test_male_matchers (__main__.TestGenderDiscovery) ... ok\n",
      "test_dosage_matchers (__main__.TestMedicineDosageDiscovery) ... ok\n",
      "test_suicidal_matchers (__main__.TestSuicidalThoughtsDiscovery) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.010s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "# Unit tests\n",
    "class TestAgeDiscovery(unittest.TestCase):\n",
    "    def test_age_matchers(self):\n",
    "        self.assertTrue(all([find_age(text) for text in age_sample_sentences]))\n",
    "        self.assertFalse(all([find_age(text) for text in no_age_sentences]))\n",
    "\n",
    "res = unittest.main(argv=[''], verbosity=3, exit=False)\n",
    "assert len(res.result.failures) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_authors_age_in_posts(idx):\n",
    "    age_idx = copy.deepcopy(idx)\n",
    "    def process_entry(author, text):\n",
    "        age = find_age(text)\n",
    "        age_idx[author]['age'] = age\n",
    "\n",
    "    for author, text in posts_and_commnets:\n",
    "        process_entry(author, text)\n",
    "    return age_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46918"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_index = identify_authors_age_in_posts(author_index)\n",
    "len(author_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authors with identified age: 1192\n"
     ]
    }
   ],
   "source": [
    "total_authors_with_age = 0\n",
    "\n",
    "for _, v in author_index.items():\n",
    "    if v['age'] != 0:\n",
    "        total_authors_with_age += 1\n",
    "\n",
    "print(f'Authors with identified age: {total_authors_with_age}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature - Migraine Triggers\n",
    "\n",
    "This section identifies authors and their triggers.  The approach to discovery of this feature is somewhat different.\n",
    "\n",
    "First we create a list of posts with word trigger(s) and then we sample those to discover sentences we can use to identify triggers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29046"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = re.compile('(trigger|triggers)', re.IGNORECASE)\n",
    "\n",
    "def trigger_filter(text):\n",
    "    if pattern.search(text, re.IGNORECASE):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "posts_with_triggers = [post for post in posts_and_commnets if trigger_filter(post[1])]\n",
    "len(posts_with_triggers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('danawl', 'Hello fellow cool kids, \\n\\nI’m wondering if any of you have screen based triggers, and notice any certain side effects. This is just out of pure curiosity. \\n\\nI, myself, am able to stare at my phone and tv screen a lot longer than I can my computer screen. I have blue light glasses, I always have “night mode” on. \\n\\nI think because I use dark mode on my phone, that helps, and I’m not staring at flat text as much on a phone / tv than I am when I’m on a computer. I’m a coding student, so my assignments consist of staring at small lines of code on a high contrast screen. \\n\\nThoughts?'),\n",
       " ('redsquirrel5000', \"So I moved from Nevada 2 years ago to Florida, I had migraines in Nevada as well, but they are a bit worse in Florida especially the humid and stormy summers.\\n\\nSome info says I should move. I'm on preventatives, but maybe there are better meds my doc is not aware of for rain or lightning and stormy weather related migraines?\\n\\n&amp;#x200B;\\n\\nMy triggers include stress, screens, bright lights, fast motion, tv's, and rain, lightning and things like that.\\n\\nI also have anxiety disorders and ocd etc.\\n\\nSome information says I should move to a more mild less rainy climate, but I don't know....its a huge expense, and no guarantee it will help that much....\\n\\nIs there any meds that work really well for weather changes? Both OTC and doc meds.... or any techniques that are helpful?\\n\\nI have to use screens for work also, which is a huge issue anywhere I go......as its a big trigger for my headaches....but I'm not ready to give up my work of 15+ years...even with the headache pain that screens cause......not ideal.....\\n\\nThoughts?  Thanks!   I'd rather not move...some people say Arizona, etc..but others say not worth moving...overall just try to control other triggers?\"),\n",
       " ('moooojojojo', 'Does anyone experience migraine trigger from leafy greens / power greens (kale, baby kale, chard spinach, arugula)?\\n\\nAte a protein bowl with some leafy greens and felt overwhelming pressure through my head and ears ~30 minutes later. Raw kale and greens were the only “new” ingredients, but I had thought magnesium rich greens were supposed to be safe….'),\n",
       " ('redsquirrel5000', \"I've had lots of prescriptions for migraine medications, and otc etc for years. \\n\\nBut I recently found that light beer (not a flavored one) can really help my migraines.\\n\\nI also have anxiety and OCD which causes tension headaches and migraines.\\n\\nTriggers include screens on computers, phones etc, flicker type lights, and motion, tv, and when it rains...not so much barometric pressure, seems to be rapid humidity changes.\\n\\nBut yeah, a light beer when the symptoms start up really helps. Just thought I'd share incase it helps anyone, it took me years to figure this out. and really helps.\"),\n",
       " ('lavalampjelly', \"So I started getting migraines as a teenager. They were debilitating, and I would have to take time off school. I've always had an aura, which used to fade and then an intense migrain pain would kick in, sending me to bed for two days. Now, I'm on my late twenties. And every so often I just get the aura with no pain. It starts off as a pinprick of static in my vision, then spreads into a big curved line, like the edge of a circle, until it fills the eye, then keeps getting bigger until it goes this lasts for about 30 mins. I didn't have one for three years, and have had two in the last two months, so I've rang my gp and waiting for a call back. When it happens I get incredibly anxious, and have to keep myself calm or I will go into a full blown panic attack. After it goes I have a very mild headache, and feel tired and run down, but honestly think that's more to do with the anxiety it enduces rather than the aura. I just want to know what others experiences are with this, do others get aura migraine without pain? Has anybody figured out any triggers, or ways to help prevent it? As I've never figured out my trigger but think it may be stress. And does anybody have advice for dealing with the anxiety it causes? Today I sat in the bath with the lights off until it went, which helped my anxiety a bit, but I worry I'll get one when I'm in work or driving.\")]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample\n",
    "posts_with_triggers[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output from the above produced lots of samples of how triggers are described:\n",
    "\n",
    "- have screen based triggers\n",
    "- My triggers include stress, screens, bright lights, fast motion, tv's, and rain, lightning and things like that\n",
    "- experience migraine trigger from leafy greens / power greens (kale, baby kale, chard spinach, arugula)?\n",
    "- Triggers include screens on computers, phones etc, flicker type lights, and motion, tv, and when it rains\n",
    "- exercise triggering migraines\n",
    "- I have identified coffee/caffeine and lack of sleep as my two main triggers\n",
    "- have any perfume brands/scents that do not trigger headaches or migraines\n",
    "- I found i can't wear perfumes, they all trigger me\n",
    "- Coffee creamers were my trigger specifically International Delight Brand\n",
    "- I can personally confirm that coffee/caffeine is a migraine trigger\n",
    "- My migraines were triggered by a stressful life event\n",
    "- Mold triggers horrifying migraines for me\n",
    "- I'll check the weather as my main trigger seems to be barometric pressure changes\n",
    "- When I'm in danger of migraines I avoid orgasm because it's a trigger for me\n",
    "- Of course certain sound trigger them\n",
    "- Sound sensitivity *triggers* migraines for me\n",
    "- Scent triggers are the primary challenge for me\n",
    "- The Covid vaccines we had did trigger migraines\n",
    "- Barometric pressure is my other trigger\n",
    "- covid can trigger nasty migraines\n",
    "- One of my triggers is disturbed sleep so sure\n",
    "- fasting is my #1 trigger\n",
    "- I found out that my migraine triggers were foods\n",
    "- Stress is my #1 trigger too\n",
    "- Bright light is my #1 trigger\n",
    "- I’m triggered by weather so it’s usually a storm or weather front that causes mine.\n",
    "- My main trigger is weather\n",
    "- Weather triggers were the easiest to be solved by a good prophylactic\n",
    "- Some of my triggers are unavoidable (like lack of sleep)\n",
    "- I realize I can’t smoke sativa or it can trigger a migraine and anxiety\n",
    "- OMG aspartame is a migraine trigger for me too\n",
    "- My worst triggers are smells/scent/odors\n",
    "- Common triggers for me though are strong scents\n",
    "- Even chocolate can trigger it with a high amount of caffeine.\n",
    "- Stress triggers tension headaches for me\n",
    "- Stress is my biggest trigger by far\n",
    "- swimming is a trigger for me\n",
    "- Stress and neck problems are my top two triggers\n",
    "- Stress is my major trigger\n",
    "- Triggers for me: Sunlight, headlights, smells (perfume and cologne and candles), stress, lack of sleep, and dark chocolate.\n",
    "- I just recently discovered lemonade as a trigger\n",
    "- my other triggers are weather, certain foods\n",
    "- Stress, weather and sugar are my triggers\n",
    "- Blood sugar swings are a primary trigger for me.\n",
    "- Cranial pressure is a trigger for migraines\n",
    "- My migraines are triggered by high air pressure\n",
    "- bright white lights are a big trigger\n",
    "- I have migraines very evidently triggered by sugar\n",
    "- Too many carbs or sugar in a meal can trigger one for me as well\n",
    "- The vaccine triggered migraines\n",
    "- migraines (no headache) triggered by sunlight and glare\n",
    "- My other triggers are barometric pressure and smells\n",
    "\n",
    "There seems to be a specific pattern here.  Most of the description of triggers are contained in one sentence and they form pattern of word trigger and some form of description or list of symptoms. This might be tough to capture with just regex, therefore we turn to  Spacy library to help with identifying what words are referred to by word trigger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To this once\n",
    "# ! python -m spacy download en_core_web_sm\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To figure out how we can capture triggers we used Spacy's dependency graph to better understand the relationship between word trigger and trigger description(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37734"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From each post take text and split it into senteces\n",
    "# and only keep sentences referring to triggers\n",
    "def get_sentences_with_triggers():\n",
    "    trigger_sentences = []\n",
    "    pattern = re.compile('(trigger|triggers)', re.IGNORECASE)\n",
    "    for post in posts_with_triggers:\n",
    "        text = post[1]\n",
    "        doc = nlp(text)\n",
    "        sentences = [str(sent) for sent in doc.sents if pattern.search(str(sent))]\n",
    "        trigger_sentences.extend(sentences)\n",
    "    return trigger_sentences\n",
    "\n",
    "trigger_sentences = get_sentences_with_triggers()\n",
    "len(trigger_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello fellow cool kids, \\n\\nI’m wondering if any of you have screen based triggers, and notice any certain side effects.',\n",
       " \"\\n\\n&amp;#x200B;\\n\\nMy triggers include stress, screens, bright lights, fast motion, tv's, and rain, lightning and things like that.\"]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take couple sample sentences\n",
    "trigger_sentences[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"3ff7704a40f142469cd76c2f0128aea3-0\" class=\"displacy\" width=\"3900\" height=\"574.5\" direction=\"ltr\" style=\"max-width: none; height: 574.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Hello</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">INTJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">fellow</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">cool</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">kids,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">\n",
       "\n",
       "</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">SPACE</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">I</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">’m</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">wondering</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">if</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">SCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">any</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">of</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">you</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">have</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2325\">screen</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2325\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2500\">based</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2500\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2675\">triggers,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2675\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2850\">and</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2850\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3025\">notice</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3025\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3200\">any</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3200\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3375\">certain</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3375\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3550\">side</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3550\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3725\">effects.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3725\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3ff7704a40f142469cd76c2f0128aea3-0-0\" stroke-width=\"2px\" d=\"M70,439.5 C70,177.0 565.0,177.0 565.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3ff7704a40f142469cd76c2f0128aea3-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">intj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,441.5 L62,429.5 78,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3ff7704a40f142469cd76c2f0128aea3-0-1\" stroke-width=\"2px\" d=\"M245,439.5 C245,264.5 560.0,264.5 560.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3ff7704a40f142469cd76c2f0128aea3-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,441.5 L237,429.5 253,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3ff7704a40f142469cd76c2f0128aea3-0-2\" stroke-width=\"2px\" d=\"M420,439.5 C420,352.0 555.0,352.0 555.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3ff7704a40f142469cd76c2f0128aea3-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,441.5 L412,429.5 428,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3ff7704a40f142469cd76c2f0128aea3-0-3\" stroke-width=\"2px\" d=\"M595,439.5 C595,89.5 1270.0,89.5 1270.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3ff7704a40f142469cd76c2f0128aea3-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,441.5 L587,429.5 603,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3ff7704a40f142469cd76c2f0128aea3-0-4\" stroke-width=\"2px\" d=\"M595,439.5 C595,352.0 730.0,352.0 730.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3ff7704a40f142469cd76c2f0128aea3-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">intj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M730.0,441.5 L738.0,429.5 722.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3ff7704a40f142469cd76c2f0128aea3-0-5\" stroke-width=\"2px\" d=\"M945,439.5 C945,264.5 1260.0,264.5 1260.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3ff7704a40f142469cd76c2f0128aea3-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945,441.5 L937,429.5 953,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3ff7704a40f142469cd76c2f0128aea3-0-6\" stroke-width=\"2px\" d=\"M1120,439.5 C1120,352.0 1255.0,352.0 1255.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3ff7704a40f142469cd76c2f0128aea3-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,441.5 L1112,429.5 1128,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3ff7704a40f142469cd76c2f0128aea3-0-7\" stroke-width=\"2px\" d=\"M1470,439.5 C1470,89.5 2145.0,89.5 2145.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3ff7704a40f142469cd76c2f0128aea3-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">mark</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1470,441.5 L1462,429.5 1478,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3ff7704a40f142469cd76c2f0128aea3-0-8\" stroke-width=\"2px\" d=\"M1645,439.5 C1645,177.0 2140.0,177.0 2140.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3ff7704a40f142469cd76c2f0128aea3-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1645,441.5 L1637,429.5 1653,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3ff7704a40f142469cd76c2f0128aea3-0-9\" stroke-width=\"2px\" d=\"M1645,439.5 C1645,352.0 1780.0,352.0 1780.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3ff7704a40f142469cd76c2f0128aea3-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1780.0,441.5 L1788.0,429.5 1772.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3ff7704a40f142469cd76c2f0128aea3-0-10\" stroke-width=\"2px\" d=\"M1820,439.5 C1820,352.0 1955.0,352.0 1955.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3ff7704a40f142469cd76c2f0128aea3-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1955.0,441.5 L1963.0,429.5 1947.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3ff7704a40f142469cd76c2f0128aea3-0-11\" stroke-width=\"2px\" d=\"M1295,439.5 C1295,2.0 2150.0,2.0 2150.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3ff7704a40f142469cd76c2f0128aea3-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">ccomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2150.0,441.5 L2158.0,429.5 2142.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3ff7704a40f142469cd76c2f0128aea3-0-12\" stroke-width=\"2px\" d=\"M2345,439.5 C2345,352.0 2480.0,352.0 2480.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3ff7704a40f142469cd76c2f0128aea3-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">npadvmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2345,441.5 L2337,429.5 2353,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3ff7704a40f142469cd76c2f0128aea3-0-13\" stroke-width=\"2px\" d=\"M2520,439.5 C2520,352.0 2655.0,352.0 2655.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3ff7704a40f142469cd76c2f0128aea3-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2520,441.5 L2512,429.5 2528,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3ff7704a40f142469cd76c2f0128aea3-0-14\" stroke-width=\"2px\" d=\"M2170,439.5 C2170,177.0 2665.0,177.0 2665.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3ff7704a40f142469cd76c2f0128aea3-0-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2665.0,441.5 L2673.0,429.5 2657.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3ff7704a40f142469cd76c2f0128aea3-0-15\" stroke-width=\"2px\" d=\"M2170,439.5 C2170,89.5 2845.0,89.5 2845.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3ff7704a40f142469cd76c2f0128aea3-0-15\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2845.0,441.5 L2853.0,429.5 2837.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3ff7704a40f142469cd76c2f0128aea3-0-16\" stroke-width=\"2px\" d=\"M2170,439.5 C2170,2.0 3025.0,2.0 3025.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3ff7704a40f142469cd76c2f0128aea3-0-16\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3025.0,441.5 L3033.0,429.5 3017.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3ff7704a40f142469cd76c2f0128aea3-0-17\" stroke-width=\"2px\" d=\"M3220,439.5 C3220,177.0 3715.0,177.0 3715.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3ff7704a40f142469cd76c2f0128aea3-0-17\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3220,441.5 L3212,429.5 3228,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3ff7704a40f142469cd76c2f0128aea3-0-18\" stroke-width=\"2px\" d=\"M3395,439.5 C3395,264.5 3710.0,264.5 3710.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3ff7704a40f142469cd76c2f0128aea3-0-18\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3395,441.5 L3387,429.5 3403,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3ff7704a40f142469cd76c2f0128aea3-0-19\" stroke-width=\"2px\" d=\"M3570,439.5 C3570,352.0 3705.0,352.0 3705.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3ff7704a40f142469cd76c2f0128aea3-0-19\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3570,441.5 L3562,429.5 3578,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3ff7704a40f142469cd76c2f0128aea3-0-20\" stroke-width=\"2px\" d=\"M3045,439.5 C3045,89.5 3720.0,89.5 3720.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3ff7704a40f142469cd76c2f0128aea3-0-20\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3720.0,441.5 L3728.0,429.5 3712.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "\n",
    "# graph word dependencies\n",
    "doc_vis = nlp(trigger_sentences[0])\n",
    "displacy.render(doc_vis, style=\"dep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"0f0498e033524c5e8d51f9e604968886-0\" class=\"displacy\" width=\"3725\" height=\"574.5\" direction=\"ltr\" style=\"max-width: none; height: 574.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">\n",
       "\n",
       "&amp;</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">SPACE</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">amp;#x200B;</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">X</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">\n",
       "\n",
       "</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">SPACE</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">My</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">triggers</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">include</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">stress,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">screens,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">bright</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">lights,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">fast</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">motion,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">tv</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2325\">'s,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2325\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2500\">and</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2500\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2675\">rain,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2675\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2850\">lightning</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2850\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3025\">and</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3025\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3200\">things</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3200\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3375\">like</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3375\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3550\">that.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3550\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0f0498e033524c5e8d51f9e604968886-0-0\" stroke-width=\"2px\" d=\"M70,439.5 C70,89.5 920.0,89.5 920.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0f0498e033524c5e8d51f9e604968886-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,441.5 L62,429.5 78,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0f0498e033524c5e8d51f9e604968886-0-1\" stroke-width=\"2px\" d=\"M70,439.5 C70,352.0 205.0,352.0 205.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0f0498e033524c5e8d51f9e604968886-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M205.0,441.5 L213.0,429.5 197.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0f0498e033524c5e8d51f9e604968886-0-2\" stroke-width=\"2px\" d=\"M420,439.5 C420,177.0 915.0,177.0 915.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0f0498e033524c5e8d51f9e604968886-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,441.5 L412,429.5 428,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0f0498e033524c5e8d51f9e604968886-0-3\" stroke-width=\"2px\" d=\"M595,439.5 C595,352.0 730.0,352.0 730.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0f0498e033524c5e8d51f9e604968886-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">poss</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,441.5 L587,429.5 603,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0f0498e033524c5e8d51f9e604968886-0-4\" stroke-width=\"2px\" d=\"M770,439.5 C770,352.0 905.0,352.0 905.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0f0498e033524c5e8d51f9e604968886-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,441.5 L762,429.5 778,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0f0498e033524c5e8d51f9e604968886-0-5\" stroke-width=\"2px\" d=\"M945,439.5 C945,352.0 1080.0,352.0 1080.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0f0498e033524c5e8d51f9e604968886-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1080.0,441.5 L1088.0,429.5 1072.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0f0498e033524c5e8d51f9e604968886-0-6\" stroke-width=\"2px\" d=\"M1120,439.5 C1120,352.0 1255.0,352.0 1255.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0f0498e033524c5e8d51f9e604968886-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1255.0,441.5 L1263.0,429.5 1247.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0f0498e033524c5e8d51f9e604968886-0-7\" stroke-width=\"2px\" d=\"M1470,439.5 C1470,352.0 1605.0,352.0 1605.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0f0498e033524c5e8d51f9e604968886-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1470,441.5 L1462,429.5 1478,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0f0498e033524c5e8d51f9e604968886-0-8\" stroke-width=\"2px\" d=\"M1295,439.5 C1295,264.5 1610.0,264.5 1610.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0f0498e033524c5e8d51f9e604968886-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1610.0,441.5 L1618.0,429.5 1602.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0f0498e033524c5e8d51f9e604968886-0-9\" stroke-width=\"2px\" d=\"M1820,439.5 C1820,352.0 1955.0,352.0 1955.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0f0498e033524c5e8d51f9e604968886-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1820,441.5 L1812,429.5 1828,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0f0498e033524c5e8d51f9e604968886-0-10\" stroke-width=\"2px\" d=\"M1645,439.5 C1645,264.5 1960.0,264.5 1960.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0f0498e033524c5e8d51f9e604968886-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1960.0,441.5 L1968.0,429.5 1952.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0f0498e033524c5e8d51f9e604968886-0-11\" stroke-width=\"2px\" d=\"M1995,439.5 C1995,352.0 2130.0,352.0 2130.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0f0498e033524c5e8d51f9e604968886-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2130.0,441.5 L2138.0,429.5 2122.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0f0498e033524c5e8d51f9e604968886-0-12\" stroke-width=\"2px\" d=\"M2170,439.5 C2170,352.0 2305.0,352.0 2305.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0f0498e033524c5e8d51f9e604968886-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2305.0,441.5 L2313.0,429.5 2297.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0f0498e033524c5e8d51f9e604968886-0-13\" stroke-width=\"2px\" d=\"M2170,439.5 C2170,264.5 2485.0,264.5 2485.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0f0498e033524c5e8d51f9e604968886-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2485.0,441.5 L2493.0,429.5 2477.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0f0498e033524c5e8d51f9e604968886-0-14\" stroke-width=\"2px\" d=\"M2170,439.5 C2170,177.0 2665.0,177.0 2665.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0f0498e033524c5e8d51f9e604968886-0-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2665.0,441.5 L2673.0,429.5 2657.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0f0498e033524c5e8d51f9e604968886-0-15\" stroke-width=\"2px\" d=\"M2695,439.5 C2695,352.0 2830.0,352.0 2830.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0f0498e033524c5e8d51f9e604968886-0-15\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2830.0,441.5 L2838.0,429.5 2822.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0f0498e033524c5e8d51f9e604968886-0-16\" stroke-width=\"2px\" d=\"M2870,439.5 C2870,352.0 3005.0,352.0 3005.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0f0498e033524c5e8d51f9e604968886-0-16\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3005.0,441.5 L3013.0,429.5 2997.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0f0498e033524c5e8d51f9e604968886-0-17\" stroke-width=\"2px\" d=\"M2870,439.5 C2870,264.5 3185.0,264.5 3185.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0f0498e033524c5e8d51f9e604968886-0-17\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3185.0,441.5 L3193.0,429.5 3177.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0f0498e033524c5e8d51f9e604968886-0-18\" stroke-width=\"2px\" d=\"M1995,439.5 C1995,2.0 3375.0,2.0 3375.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0f0498e033524c5e8d51f9e604968886-0-18\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3375.0,441.5 L3383.0,429.5 3367.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0f0498e033524c5e8d51f9e604968886-0-19\" stroke-width=\"2px\" d=\"M3395,439.5 C3395,352.0 3530.0,352.0 3530.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0f0498e033524c5e8d51f9e604968886-0-19\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3530.0,441.5 L3538.0,429.5 3522.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc_vis = nlp(trigger_sentences[1])\n",
    "displacy.render(doc_vis, style=\"dep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From couple examples shown above we can see that we can identify word `trigger(s)` as NOUN part of speech and then from that point we can look at the dependencies.  In all cases triggers will be NOUN but they will vary in dependency type so that they can be dobj or conj or npadvmod.\n",
    "\n",
    "Based on this we can write a function that will look for work `trigger(s)` that is NOUN and can be `nsubj`, `dobj`, or `pobj`.  Once we capture part of speech and dependency we can start looking for the triggers based on the rules above.\n",
    "\n",
    "Here is the resulting function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all of the triggers and store them in a list\n",
    "def find_unfiltered_triggers(nlp, text):\n",
    "    triggers = []\n",
    "    doc = nlp(text)\n",
    "    dep_type = None\n",
    "    for token in doc:\n",
    "        if (token.dep_ == 'nsubj' or token.dep_ == 'dobj' or token.dep_ == 'pobj') \\\n",
    "            and re.search('(trigger|triggers)', token.text, re.IGNORECASE):\n",
    "            dep_type = token.dep_\n",
    "        if token.pos_ == 'NOUN' and token.dep_ != dep_type and (token.dep_ == 'punc' or token.dep_ == 'dobj' or token.dep_ == 'conj'):\n",
    "            triggers.append(token.text)\n",
    "    return triggers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We called above function `find_unfiltered_triggers` because we know they we will find some nouns that are not actual triggers.  This happens because we are unable to build tight enough rules to account for people writing in different ways or even not adhering to grammar.\n",
    "\n",
    "However, we decided to run this and see how many total triggers we can identify and maybe if there aren't too many we could just prune those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41732"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "unfiltered_triggers = []\n",
    "for trigger_sentence in trigger_sentences:\n",
    "    unfiltered_triggers.extend(find_unfiltered_triggers(nlp, trigger_sentence))\n",
    "\n",
    "len(unfiltered_triggers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a lot of triggers but there are duplicates in there.  So for the next step we count each trigger type and sort to see which are the most frequent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('migraines', 3826),\n",
       " ('migraine', 3093),\n",
       " ('triggers', 653),\n",
       " ('pain', 510),\n",
       " ('stress', 505),\n",
       " ('foods', 466),\n",
       " ('things', 464),\n",
       " ('headaches', 460),\n",
       " ('lot', 441),\n",
       " ('attack', 407),\n",
       " ('headache', 389),\n",
       " ('changes', 388),\n",
       " ('symptoms', 381),\n",
       " ('lights', 318),\n",
       " ('alcohol', 314),\n",
       " ('sleep', 270),\n",
       " ('food', 267),\n",
       " ('caffeine', 258),\n",
       " ('attacks', 257),\n",
       " ('diet', 248),\n",
       " ('injections', 244),\n",
       " ('weather', 232),\n",
       " ('pressure', 229),\n",
       " ('diary', 220),\n",
       " ('time', 217),\n",
       " ('chocolate', 210),\n",
       " ('anxiety', 208),\n",
       " ('patterns', 201),\n",
       " ('sugar', 199),\n",
       " ('dehydration', 198),\n",
       " ('light', 188),\n",
       " ('trigger', 188),\n",
       " ('issues', 172),\n",
       " ('neck', 164),\n",
       " ('hormones', 158),\n",
       " ('exercise', 157),\n",
       " ('idea', 149),\n",
       " ('meds', 149),\n",
       " ('wine', 140),\n",
       " ('water', 137),\n",
       " ('lack', 133),\n",
       " ('information', 129),\n",
       " ('days', 125),\n",
       " ('coffee', 124),\n",
       " ('head', 121),\n",
       " ('meals', 120),\n",
       " ('cheese', 113),\n",
       " ('journal', 112),\n",
       " ('list', 112),\n",
       " ('points', 108),\n",
       " ('tension', 108),\n",
       " ('one', 103),\n",
       " ('heat', 102),\n",
       " ('medication', 101),\n",
       " ('people', 100),\n",
       " ('sense', 99),\n",
       " ('relief', 99),\n",
       " ('others', 98),\n",
       " ('thing', 97),\n",
       " ('lots', 96),\n",
       " ('ones', 96),\n",
       " ('nausea', 95),\n",
       " ('severity', 91),\n",
       " ('life', 91),\n",
       " ('track', 91),\n",
       " ('allergies', 90),\n",
       " ('day', 88),\n",
       " ('way', 87),\n",
       " ('aura', 86),\n",
       " ('cycle', 86),\n",
       " ('smells', 85),\n",
       " ('glasses', 85),\n",
       " ('frequency', 83),\n",
       " ('work', 81),\n",
       " ('app', 80),\n",
       " ('schedule', 79),\n",
       " ('change', 79),\n",
       " ('levels', 78),\n",
       " ('stuff', 78),\n",
       " ('humidity', 77),\n",
       " ('problem', 77),\n",
       " ('sensitivity', 77),\n",
       " ('care', 77),\n",
       " ('problems', 73),\n",
       " ('amount', 72),\n",
       " ('dairy', 71),\n",
       " ('control', 71),\n",
       " ('therapy', 71),\n",
       " ('muscles', 70),\n",
       " ('sweeteners', 70),\n",
       " ('sunglasses', 70),\n",
       " ('job', 70),\n",
       " ('smell', 69),\n",
       " ('scents', 68),\n",
       " ('kind', 67),\n",
       " ('shoulders', 66),\n",
       " ('point', 66),\n",
       " ('body', 65),\n",
       " ('noise', 65),\n",
       " ('hours', 65),\n",
       " ('type', 65),\n",
       " ('auras', 64),\n",
       " ('mine', 64),\n",
       " ('pattern', 64),\n",
       " ('years', 62),\n",
       " ('difference', 61),\n",
       " ('beer', 61),\n",
       " ('effect', 60),\n",
       " ('doctor', 60),\n",
       " ('drinks', 60),\n",
       " ('management', 59),\n",
       " ('massage', 58),\n",
       " ('ton', 58),\n",
       " ('sun', 58),\n",
       " ('response', 57),\n",
       " ('bit', 57),\n",
       " ('neurologist', 57),\n",
       " ('supplements', 57),\n",
       " ('lighting', 56),\n",
       " ('medications', 56),\n",
       " ('episode', 55),\n",
       " ('eyes', 55),\n",
       " ('blocks', 55),\n",
       " ('meats', 55),\n",
       " ('experience', 54),\n",
       " ('products', 54),\n",
       " ('threshold', 54),\n",
       " ('treatments', 54),\n",
       " ('inflammation', 54),\n",
       " ('perfume', 54),\n",
       " ('bunch', 53),\n",
       " ('effects', 53),\n",
       " ('teeth', 53),\n",
       " ('smoke', 52),\n",
       " ('treatment', 52),\n",
       " ('look', 52),\n",
       " ('types', 49),\n",
       " ('amp', 49),\n",
       " ('hair', 49),\n",
       " ('perfumes', 48),\n",
       " ('weight', 48),\n",
       " ('issue', 48),\n",
       " ('period', 47),\n",
       " ('sound', 47),\n",
       " ('factors', 47),\n",
       " ('depression', 47),\n",
       " ('screens', 46),\n",
       " ('carbs', 46),\n",
       " ('chance', 45),\n",
       " ('odors', 45),\n",
       " ('cause', 45),\n",
       " ('meal', 44),\n",
       " ('scent', 44),\n",
       " ('log', 44),\n",
       " ('advice', 44),\n",
       " ('attention', 43),\n",
       " ('activity', 43),\n",
       " ('nitrates', 43),\n",
       " ('episodes', 42),\n",
       " ('feeling', 41),\n",
       " ('noises', 41),\n",
       " ('dose', 40),\n",
       " ('level', 40),\n",
       " ('luck', 40),\n",
       " ('success', 40),\n",
       " ('exposure', 40),\n",
       " ('tips', 39),\n",
       " ('posture', 39),\n",
       " ('reaction', 39),\n",
       " ('eye', 39),\n",
       " ('hunger', 39),\n",
       " ('couple', 38),\n",
       " ('sort', 37),\n",
       " ('part', 37),\n",
       " ('lifestyle', 37),\n",
       " ('sounds', 36),\n",
       " ('help', 36),\n",
       " ('jaw', 36),\n",
       " ('fatigue', 36),\n",
       " ('vomiting', 36),\n",
       " ('nerves', 35),\n",
       " ('exercises', 35),\n",
       " ('research', 35),\n",
       " ('error', 35),\n",
       " ('times', 34),\n",
       " ('magnesium', 34),\n",
       " ('mask', 34),\n",
       " ('kinds', 33),\n",
       " ('seizures', 33),\n",
       " ('lol', 33),\n",
       " ('strain', 33),\n",
       " ('sunlight', 33),\n",
       " ('diets', 33),\n",
       " ('symptom', 33),\n",
       " ('causes', 33),\n",
       " ('condition', 33),\n",
       " ('preservatives', 32),\n",
       " ('meat', 32),\n",
       " ('rest', 32),\n",
       " ('smoking', 32),\n",
       " ('disorder', 31),\n",
       " ('shots', 31),\n",
       " ('activities', 31),\n",
       " ('drink', 31),\n",
       " ('role', 31),\n",
       " ('brain', 30),\n",
       " ('%', 30),\n",
       " ('intensity', 30),\n",
       " ('trouble', 30),\n",
       " ('book', 30),\n",
       " ('article', 30),\n",
       " ('months', 30),\n",
       " ('tea', 30),\n",
       " ('cheeses', 29),\n",
       " ('number', 29),\n",
       " ('rate', 29),\n",
       " ('plan', 29),\n",
       " ('chemicals', 29),\n",
       " ('muscle', 29),\n",
       " ('acupuncture', 29),\n",
       " ('onions', 29),\n",
       " ('bananas', 29),\n",
       " ('habits', 28),\n",
       " ('impact', 28),\n",
       " ('test', 28),\n",
       " ('avoidance', 28),\n",
       " ('ways', 27),\n",
       " ('triptans', 27),\n",
       " ('msg', 27),\n",
       " ('oil', 27),\n",
       " ('pill', 27),\n",
       " ('drugs', 27),\n",
       " ('signs', 26),\n",
       " ('tolerance', 26),\n",
       " ('vertigo', 26),\n",
       " ('soda', 26),\n",
       " ('glass', 26),\n",
       " ('combination', 25),\n",
       " ('air', 25),\n",
       " ('quality', 25),\n",
       " ('medicine', 25),\n",
       " ('yoga', 25),\n",
       " ('fluctuations', 25),\n",
       " ('nerve', 24),\n",
       " ('soy', 24),\n",
       " ('release', 24),\n",
       " ('drop', 24),\n",
       " ('system', 24),\n",
       " ('note', 24),\n",
       " ('pills', 24),\n",
       " ('question', 24),\n",
       " ('post', 24),\n",
       " ('amounts', 24),\n",
       " ('shot', 24),\n",
       " ('form', 24),\n",
       " ('storms', 24),\n",
       " ('intake', 24),\n",
       " ('history', 24),\n",
       " ('-', 24),\n",
       " ('week', 24),\n",
       " ('bread', 24),\n",
       " ('duration', 24),\n",
       " ('surgery', 24),\n",
       " ('nuts', 23),\n",
       " ('candles', 23),\n",
       " ('asthma', 23),\n",
       " ('tons', 23),\n",
       " ('disease', 23),\n",
       " ('weeks', 23),\n",
       " ('increase', 23),\n",
       " ('cup', 23),\n",
       " ('games', 23),\n",
       " ('vision', 23),\n",
       " ('salt', 23),\n",
       " ('sinuses', 23),\n",
       " ('rain', 22),\n",
       " ('conditions', 22),\n",
       " ('clue', 22),\n",
       " ('risk', 22),\n",
       " ('suggestions', 22),\n",
       " ('hydration', 21),\n",
       " ('friends', 21),\n",
       " ('ingredients', 21),\n",
       " ('swings', 21),\n",
       " ('situation', 21),\n",
       " ('experiences', 21),\n",
       " ('results', 21),\n",
       " ('glare', 21),\n",
       " ('house', 21),\n",
       " ('periods', 21),\n",
       " ('illness', 21),\n",
       " ('diagnosis', 21),\n",
       " ('screen', 21),\n",
       " ('loss', 21),\n",
       " ('additives', 20),\n",
       " ('environment', 20),\n",
       " ('info', 20),\n",
       " ('oils', 20),\n",
       " ('reactions', 20),\n",
       " ('spasms', 20),\n",
       " ('sugars', 20),\n",
       " ('tricks', 19),\n",
       " ('ideas', 19),\n",
       " ('balance', 19),\n",
       " ('imbalance', 19),\n",
       " ('sensitivities', 19),\n",
       " ('fragrances', 19),\n",
       " ('break', 19),\n",
       " ('lavender', 19),\n",
       " ('link', 19),\n",
       " ('routine', 19),\n",
       " ('sensation', 19),\n",
       " ('sinus', 19),\n",
       " ('cream', 19),\n",
       " ('notes', 19),\n",
       " ('handle', 19),\n",
       " ('buddy', 19),\n",
       " ('options', 19),\n",
       " ('tv', 18),\n",
       " ('correlation', 18),\n",
       " ('class', 18),\n",
       " ('shoulder', 18),\n",
       " ('preventatives', 18),\n",
       " ('fog', 18),\n",
       " ('doctors', 18),\n",
       " ('butter', 18),\n",
       " ('fruits', 18),\n",
       " ('process', 18),\n",
       " ('block', 18),\n",
       " ('mind', 18),\n",
       " ('schedules', 17),\n",
       " ('nose', 17),\n",
       " ('seizure', 17),\n",
       " ('side', 17),\n",
       " ('wheat', 17),\n",
       " ('flare', 17),\n",
       " ('drops', 17),\n",
       " ('situations', 17),\n",
       " ('plenty', 17),\n",
       " ('data', 17),\n",
       " ('face', 17),\n",
       " ('electrolytes', 17),\n",
       " ('tracking', 17),\n",
       " ('while', 17),\n",
       " ('reason', 17),\n",
       " ('packs', 17),\n",
       " ('neuro', 17),\n",
       " ('pillow', 17),\n",
       " ('shit', 17),\n",
       " ('milk', 17),\n",
       " ('garlic', 17),\n",
       " ('reduction', 17),\n",
       " ('eggs', 16),\n",
       " ('withdrawal', 16),\n",
       " ('bottle', 16),\n",
       " ('sickness', 16),\n",
       " ('position', 16),\n",
       " ('rebound', 16),\n",
       " ('chiropractor', 16),\n",
       " ('therapist', 16),\n",
       " ('citrus', 16),\n",
       " ('meditation', 16),\n",
       " ('event', 16),\n",
       " ('exertion', 16),\n",
       " ('solution', 16),\n",
       " ('mold', 16),\n",
       " ('injury', 16),\n",
       " ('place', 16),\n",
       " ('half', 16),\n",
       " ('cravings', 16),\n",
       " ('allergy', 16),\n",
       " ('evidence', 16),\n",
       " ('photophobia', 16),\n",
       " ('appointment', 15),\n",
       " ('dizziness', 15),\n",
       " ('specialist', 15),\n",
       " ('relaxation', 15),\n",
       " ('crying', 15),\n",
       " ('infection', 15),\n",
       " ('preventative', 15),\n",
       " ('area', 15),\n",
       " ('knots', 15),\n",
       " ('stomach', 15),\n",
       " ('keto', 15),\n",
       " ('movement', 15),\n",
       " ('onset', 15),\n",
       " ('vessels', 15),\n",
       " ('spray', 15),\n",
       " ('menstruation', 15),\n",
       " ('friend', 15),\n",
       " ('combo', 15),\n",
       " ('family', 15),\n",
       " ('remedies', 15),\n",
       " ('anger', 15),\n",
       " ('variety', 15),\n",
       " ('warning', 15),\n",
       " ('moment', 15),\n",
       " ('study', 15),\n",
       " ('articles', 15),\n",
       " ('temples', 14),\n",
       " ('ability', 14),\n",
       " ('sorts', 14),\n",
       " ('sulfites', 14),\n",
       " ('massages', 14),\n",
       " ('weights', 14),\n",
       " ('vaccine', 14),\n",
       " ('cardio', 14),\n",
       " ('pork', 14),\n",
       " ('progesterone', 14),\n",
       " ('summer', 14),\n",
       " ('month', 14),\n",
       " ('cologne', 14),\n",
       " ('damage', 14),\n",
       " ('minutes', 14),\n",
       " ('lunch', 14),\n",
       " ('fact', 14),\n",
       " ('tyramine', 14),\n",
       " ('methods', 14),\n",
       " ('deprivation', 14),\n",
       " ('phosphate', 14),\n",
       " ('plugs', 13),\n",
       " ('questions', 13),\n",
       " ('case', 13),\n",
       " ('hypoglycemia', 13),\n",
       " ('abortives', 13),\n",
       " ('peppermint', 13),\n",
       " ('hat', 13),\n",
       " ('aspartame', 13),\n",
       " ('movements', 13),\n",
       " ('kids', 13),\n",
       " ('migranes', 13),\n",
       " ('pains', 13),\n",
       " ('breath', 13),\n",
       " ('doses', 13),\n",
       " ('emotions', 13),\n",
       " ('difficulty', 13),\n",
       " ('syndrome', 13),\n",
       " ('needling', 13),\n",
       " ('cigarettes', 13),\n",
       " ('dogs', 13),\n",
       " ('rebounds', 13),\n",
       " ('breakfast', 13),\n",
       " ('spots', 13),\n",
       " ('health', 13),\n",
       " ('corn', 13),\n",
       " ('techniques', 13),\n",
       " ('solutions', 13),\n",
       " ('medicines', 13),\n",
       " ('theory', 13),\n",
       " ('shifts', 13),\n",
       " ('fresheners', 12),\n",
       " ('spot', 12),\n",
       " ('office', 12),\n",
       " ('temperature', 12),\n",
       " ('school', 12),\n",
       " ('movies', 12),\n",
       " ('flow', 12),\n",
       " ('storm', 12),\n",
       " ('breathing', 12),\n",
       " ('chips', 12),\n",
       " ('nutrition', 12),\n",
       " ('start', 12),\n",
       " ('responses', 12),\n",
       " ('fear', 12),\n",
       " ('weed', 12),\n",
       " ('lists', 12),\n",
       " ('indoors', 12),\n",
       " ('gum', 12),\n",
       " ('try', 12),\n",
       " ('thoughts', 12),\n",
       " ('connection', 12),\n",
       " ('pair', 12),\n",
       " ('breaks', 12),\n",
       " ('vinegar', 12),\n",
       " ('set', 12),\n",
       " ('item', 12),\n",
       " ('spikes', 12),\n",
       " ('wonders', 12),\n",
       " ('injection', 11),\n",
       " ('congestion', 11),\n",
       " ('panic', 11),\n",
       " ('exhaustion', 11),\n",
       " ('zones', 11),\n",
       " ('use', 11),\n",
       " ('journals', 11),\n",
       " ('window', 11),\n",
       " ('dog', 11),\n",
       " ('tomatoes', 11),\n",
       " ('sauce', 11),\n",
       " ('plans', 11),\n",
       " ('visits', 11),\n",
       " ('hope', 11),\n",
       " ('person', 11),\n",
       " ('device', 11),\n",
       " ('items', 11),\n",
       " ('testing', 11),\n",
       " ('contacts', 11),\n",
       " ('apps', 11),\n",
       " ('fun', 11),\n",
       " ('range', 11),\n",
       " ('stroke', 11),\n",
       " ('posts', 11),\n",
       " ('game', 11),\n",
       " ('TV', 11),\n",
       " ('sweetener', 11),\n",
       " ('ball', 11),\n",
       " ('mom', 11),\n",
       " ('reliefs', 11),\n",
       " ('energy', 11),\n",
       " ('sex', 11),\n",
       " ('mechanisms', 11),\n",
       " ('topamax', 11),\n",
       " ('improvement', 11),\n",
       " ('hives', 11),\n",
       " ('ibuprofen', 11),\n",
       " ('dust', 11),\n",
       " ('neuralgia', 11),\n",
       " ('answer', 11),\n",
       " ('therapies', 11),\n",
       " ('drug', 11),\n",
       " ('rice', 11),\n",
       " ('sweets', 11),\n",
       " ('state', 11),\n",
       " ('phone', 11),\n",
       " ('fronts', 11),\n",
       " ('source', 11),\n",
       " ('fragrance', 10),\n",
       " ('cycles', 10),\n",
       " ('mg', 10),\n",
       " ('money', 10),\n",
       " ('mood', 10),\n",
       " ('understanding', 10),\n",
       " ('potential', 10),\n",
       " ('groups', 10),\n",
       " ('dessert', 10),\n",
       " ('reflux', 10),\n",
       " ('snack', 10),\n",
       " ('flavor', 10),\n",
       " ('protein', 10),\n",
       " ('ingredient', 10),\n",
       " ('tests', 10),\n",
       " ('tracker', 10),\n",
       " ('altitude', 10),\n",
       " ('tannins', 10),\n",
       " ('approach', 10),\n",
       " ('cure', 10),\n",
       " ('adjustments', 10),\n",
       " ('nap', 10),\n",
       " ('stretches', 10),\n",
       " ('onion', 10),\n",
       " ('flashes', 10),\n",
       " ('back', 10),\n",
       " ('evening', 10),\n",
       " ('places', 10),\n",
       " ('bulbs', 10),\n",
       " ('prescription', 10),\n",
       " ('picture', 10),\n",
       " ('coworker', 10),\n",
       " ('brightness', 10),\n",
       " ('wines', 10),\n",
       " ('identification', 10),\n",
       " ('disorders', 10),\n",
       " ('hallucinations', 10),\n",
       " ('brains', 10),\n",
       " ('hell', 9),\n",
       " ('banana', 9),\n",
       " ('tinnitus', 9),\n",
       " ('painkillers', 9),\n",
       " ('veggies', 9),\n",
       " ('taste', 9),\n",
       " ('sip', 9),\n",
       " ('peanuts', 9),\n",
       " ('vasodilation', 9),\n",
       " ('B2', 9),\n",
       " ('diarrhea', 9),\n",
       " ('coke', 9),\n",
       " ('consumption', 9),\n",
       " ('insomnia', 9),\n",
       " ('answers', 9),\n",
       " ('carb', 9),\n",
       " ('career', 9),\n",
       " ('computer', 9),\n",
       " ('music', 9),\n",
       " ('ears', 9),\n",
       " ('headphones', 9),\n",
       " ('sub', 9),\n",
       " ('training', 9),\n",
       " ('juice', 9),\n",
       " ('environments', 9),\n",
       " ('possibility', 9),\n",
       " ('hands', 9),\n",
       " ('piece', 9),\n",
       " ('trial', 9),\n",
       " ('right', 9),\n",
       " ('detergent', 9),\n",
       " ('crap', 9),\n",
       " ('monitors', 9),\n",
       " ('record', 9),\n",
       " ('stiffness', 9),\n",
       " ('reports', 9),\n",
       " ('events', 9),\n",
       " ('room', 9),\n",
       " ('disruption', 9),\n",
       " ('flavors', 9),\n",
       " ('workouts', 9),\n",
       " ('tiredness', 9),\n",
       " ('disturbances', 9),\n",
       " ('elimination', 9),\n",
       " ('links', 9),\n",
       " ('wavelengths', 9),\n",
       " ('fumes', 9),\n",
       " ('motion', 8),\n",
       " ('pack', 8),\n",
       " ('sessions', 8),\n",
       " ('sensations', 8),\n",
       " ('bucket', 8),\n",
       " ('flight', 8),\n",
       " ('sports', 8),\n",
       " ('curtains', 8),\n",
       " ('classes', 8),\n",
       " ('tooth', 8),\n",
       " ('mouth', 8),\n",
       " ('blood', 8),\n",
       " ('majority', 8),\n",
       " ('vitamins', 8),\n",
       " ('hangovers', 8),\n",
       " ('shower', 8),\n",
       " ('propranolol', 8),\n",
       " ('cold', 8),\n",
       " ('numbness', 8),\n",
       " ('mushrooms', 8),\n",
       " ('ovulation', 8),\n",
       " ('confusion', 8),\n",
       " ('dinner', 8),\n",
       " ('estrogen', 8),\n",
       " ('bag', 8),\n",
       " ('trauma', 8),\n",
       " ('powder', 8),\n",
       " ('rides', 8),\n",
       " ('patients', 8),\n",
       " ('travel', 8),\n",
       " ('lotions', 8),\n",
       " ('pickles', 8),\n",
       " ('paint', 8),\n",
       " ('thought', 8),\n",
       " ('earplugs', 8),\n",
       " ('irritation', 8),\n",
       " ('deal', 8),\n",
       " ('syrup', 8),\n",
       " ('colors', 8),\n",
       " ('triptan', 8),\n",
       " ('stimuli', 8),\n",
       " ('thunderstorms', 8),\n",
       " ('jobs', 8),\n",
       " ('pizza', 8),\n",
       " ('exhaust', 8),\n",
       " ('spike', 8),\n",
       " ('showers', 8),\n",
       " ('aspirin', 8),\n",
       " ('series', 8),\n",
       " ('avocados', 8),\n",
       " ('chicken', 8),\n",
       " ('codeine', 8),\n",
       " ('pollen', 8),\n",
       " ('apples', 8),\n",
       " ('chemical', 8),\n",
       " ('ice', 8),\n",
       " ('botox', 8),\n",
       " ('intolerance', 8),\n",
       " ('length', 8),\n",
       " ('pasta', 8),\n",
       " ('bacon', 8),\n",
       " ('fish', 8),\n",
       " ('mix', 8),\n",
       " ('insight', 8),\n",
       " ('night', 8),\n",
       " ('likelihood', 8),\n",
       " ('exam', 8),\n",
       " ('bar', 8),\n",
       " ('diaries', 8),\n",
       " ('fruit', 8),\n",
       " ('movie', 8),\n",
       " ('honey', 8),\n",
       " ('words', 8),\n",
       " ('option', 8),\n",
       " ('details', 8),\n",
       " ('phones', 7),\n",
       " ('orgasm', 7),\n",
       " ('fasting', 7),\n",
       " ('grains', 7),\n",
       " ('connections', 7),\n",
       " ('sodas', 7),\n",
       " ('steps', 7),\n",
       " ('strategies', 7),\n",
       " ('input', 7),\n",
       " ('bra', 7),\n",
       " ('swelling', 7),\n",
       " ('tears', 7),\n",
       " ('yeast', 7),\n",
       " ('support', 7),\n",
       " ('sulfates', 7),\n",
       " ('infections', 7),\n",
       " ('alarm', 7),\n",
       " ('end', 7),\n",
       " ('gasoline', 7),\n",
       " ('dots', 7),\n",
       " ('year', 7),\n",
       " ('cascade', 7),\n",
       " ('beans', 7),\n",
       " ('switch', 7),\n",
       " ('vegan', 7),\n",
       " ('stimulation', 7),\n",
       " ('suspicion', 7),\n",
       " ('receptors', 7),\n",
       " ('concussion', 7),\n",
       " ('degree', 7),\n",
       " ('women', 7),\n",
       " ('recommendations', 7),\n",
       " ('neurologists', 7),\n",
       " ('round', 7),\n",
       " ('liquor', 7),\n",
       " ('home', 7),\n",
       " ('needles', 7),\n",
       " ('baby', 7),\n",
       " ('trip', 7),\n",
       " ('sufferers', 7),\n",
       " ('masks', 7),\n",
       " ('product', 7),\n",
       " ('towel', 7),\n",
       " ('prevention', 7),\n",
       " ('arm', 7),\n",
       " ('tendency', 7),\n",
       " ('world', 7),\n",
       " ('deodorant', 7),\n",
       " ('histamine', 7),\n",
       " ('epilepsy', 7),\n",
       " ('cleaners', 7),\n",
       " ('odor', 7),\n",
       " ('story', 7),\n",
       " ('bath', 7),\n",
       " ('cups', 7),\n",
       " ('_', 7),\n",
       " ('load', 7),\n",
       " ('conversation', 7),\n",
       " ('progress', 7),\n",
       " ('loads', 7),\n",
       " ('dosage', 7),\n",
       " ('spine', 7),\n",
       " ('pad', 7),\n",
       " ('feelings', 7),\n",
       " ('beers', 7),\n",
       " ('gaming', 7),\n",
       " ('thanks', 7),\n",
       " ('choices', 7),\n",
       " ('biofeedback', 7),\n",
       " ('comment', 7),\n",
       " ('fluids', 7),\n",
       " ('gabapentin', 7),\n",
       " ('suggestion', 7),\n",
       " ('trick', 7),\n",
       " ('relaxers', 7),\n",
       " ('strawberries', 7),\n",
       " ('rounds', 7),\n",
       " ('handful', 7),\n",
       " ('alcohols', 7),\n",
       " ('dye', 7),\n",
       " ('factor', 7),\n",
       " ('antidepressants', 7),\n",
       " ('vegetables', 7),\n",
       " ('spinach', 6),\n",
       " ('opinion', 6),\n",
       " ('workout', 6),\n",
       " ('thresholds', 6),\n",
       " ('power', 6),\n",
       " ('antibiotics', 6),\n",
       " ('med', 6),\n",
       " ('none', 6),\n",
       " ('space', 6),\n",
       " ('heart', 6),\n",
       " ('accommodations', 6),\n",
       " ('decrease', 6),\n",
       " ('extract', 6),\n",
       " ('seconds', 6),\n",
       " ('bleach', 6),\n",
       " ('annatto', 6),\n",
       " ('video', 6),\n",
       " ('dysfunction', 6),\n",
       " ('weakness', 6),\n",
       " ('guard', 6),\n",
       " ('discomfort', 6),\n",
       " ('mechanism', 6),\n",
       " ('stories', 6),\n",
       " ('nicotine', 6),\n",
       " ('tools', 6),\n",
       " ('appointments', 6),\n",
       " ('needle', 6),\n",
       " ('prodrome', 6),\n",
       " ('subreddit', 6),\n",
       " ('driving', 6),\n",
       " ('search', 6),\n",
       " ('candle', 6),\n",
       " ('result', 6),\n",
       " ('hand', 6),\n",
       " ('wash', 6),\n",
       " ('windows', 6),\n",
       " ('naps', 6),\n",
       " ('thinking', 6),\n",
       " ('component', 6),\n",
       " ('finger', 6),\n",
       " ('potassium', 6),\n",
       " ('group', 6),\n",
       " ('septum', 6),\n",
       " ('chronic', 6),\n",
       " ('waves', 6),\n",
       " ('text', 6),\n",
       " ('sodium', 6),\n",
       " ('wind', 6),\n",
       " ('preventives', 6),\n",
       " ('cluster', 6),\n",
       " ('laptop', 6),\n",
       " ('grapes', 6),\n",
       " ('commute', 6),\n",
       " ('stressors', 6),\n",
       " ('method', 6),\n",
       " ('folks', 6),\n",
       " ('devices', 6),\n",
       " ('hats', 6),\n",
       " ('pepper', 6),\n",
       " ('pepperoni', 6),\n",
       " ('timing', 6),\n",
       " ('walks', 6),\n",
       " ('effectiveness', 6),\n",
       " ('studies', 6),\n",
       " ('thread', 6),\n",
       " ('fluorescent', 6),\n",
       " ('blockers', 6),\n",
       " ('building', 6),\n",
       " ('co', 6),\n",
       " ('sanitizer', 6),\n",
       " ('relationship', 6),\n",
       " ('hangover', 6),\n",
       " ('diffuser', 6),\n",
       " ('actions', 6),\n",
       " ('headlights', 6),\n",
       " ('migrane', 6),\n",
       " ('route', 6),\n",
       " ('aspect', 6),\n",
       " ('ginger', 6),\n",
       " ('serotonin', 6),\n",
       " ('notebook', 6),\n",
       " ('need', 6),\n",
       " ('tightness', 6),\n",
       " ('sprays', 6),\n",
       " ('tissue', 6),\n",
       " ('reading', 6),\n",
       " ('location', 6),\n",
       " ('infusions', 6),\n",
       " ('feel', 5),\n",
       " ('effort', 5),\n",
       " ('incense', 5),\n",
       " ('feedback', 5),\n",
       " ('awareness', 5),\n",
       " ('shampoo', 5),\n",
       " ('go', 5),\n",
       " ('barometric', 5),\n",
       " ('check', 5),\n",
       " ('skull', 5),\n",
       " ('label', 5),\n",
       " ('fats', 5),\n",
       " ('virus', 5),\n",
       " ('college', 5),\n",
       " ('daughter', 5),\n",
       " ('clenching', 5),\n",
       " ('sides', 5),\n",
       " ('up', 5),\n",
       " ('rooms', 5),\n",
       " ('brands', 5),\n",
       " ('clothes', 5),\n",
       " ('coincidence', 5),\n",
       " ('physio', 5),\n",
       " ('stretching', 5),\n",
       " ('colognes', 5),\n",
       " ('ketones', 5),\n",
       " ('migraineurs', 5),\n",
       " ('following', 5),\n",
       " ('spices', 5),\n",
       " ('allergens', 5),\n",
       " ('potatoes', 5),\n",
       " ('bodies', 5),\n",
       " ('line', 5),\n",
       " ('endorphins', 5),\n",
       " ('chances', 5),\n",
       " ('skin', 5),\n",
       " ('spring', 5),\n",
       " ('fall', 5),\n",
       " ('sheet', 5),\n",
       " ('balls', 5),\n",
       " ('sucralose', 5),\n",
       " ('candy', 5),\n",
       " ('monitor', 5),\n",
       " ('pulse', 5),\n",
       " ('website', 5),\n",
       " ('reflex', 5),\n",
       " ('age', 5),\n",
       " ('children', 5),\n",
       " ('soap', 5),\n",
       " ('status', 5),\n",
       " ('bottles', 5),\n",
       " ('experiment', 5),\n",
       " ('glutamate', 5),\n",
       " ('calendar', 5),\n",
       " ('excedrin', 5),\n",
       " ('hormone', 5),\n",
       " ('instability', 5),\n",
       " ('additive', 5),\n",
       " ('abortive', 5),\n",
       " ('leg', 5),\n",
       " ('relaxer', 5),\n",
       " ('term', 5),\n",
       " ('clusters', 5),\n",
       " ('spreadsheet', 5),\n",
       " ('blueberries', 5),\n",
       " ('flickering', 5),\n",
       " ('freeze', 5),\n",
       " ('snacks', 5),\n",
       " ('pathways', 5),\n",
       " ('fingers', 5),\n",
       " ('base', 5),\n",
       " ('phase', 5),\n",
       " ('calories', 5),\n",
       " ('calcium', 5),\n",
       " ('images', 5),\n",
       " ('visit', 5),\n",
       " ('peas', 5),\n",
       " ('morning', 5),\n",
       " ('insurance', 5),\n",
       " ('vodka', 5),\n",
       " ('traps', 5),\n",
       " ('lenses', 5),\n",
       " ('arms', 5),\n",
       " ('knot', 5),\n",
       " ('version', 5),\n",
       " ('fire', 5),\n",
       " ('concept', 5),\n",
       " ('drinking', 5),\n",
       " ('cane', 5),\n",
       " ('comments', 5),\n",
       " ('oxygen', 5),\n",
       " ('tingling', 5),\n",
       " ('sources', 5),\n",
       " ('whiff', 5),\n",
       " ('weekends', 5),\n",
       " ('hour', 5),\n",
       " ('sausage', 5),\n",
       " ('nitrites', 5),\n",
       " ('aimovig', 5),\n",
       " ('hygiene', 5),\n",
       " ('seeds', 5),\n",
       " ('exams', 5),\n",
       " ('bike', 5),\n",
       " ('boom', 5),\n",
       " ('decision', 5),\n",
       " ('member', 5),\n",
       " ('️', 5),\n",
       " ('behavior', 5),\n",
       " ('cures', 5),\n",
       " ('menopause', 5),\n",
       " ('mindfulness', 5),\n",
       " ('sign', 5),\n",
       " ('ups', 5),\n",
       " ('ponytail', 5),\n",
       " ('warnings', 5),\n",
       " ('labels', 5),\n",
       " ('tree', 5),\n",
       " ('walk', 5),\n",
       " ('headbands', 5),\n",
       " ('temperatures', 5),\n",
       " ('signals', 5),\n",
       " ('cry', 5),\n",
       " ('shrimp', 5),\n",
       " ('bathroom', 5),\n",
       " ('craving', 5),\n",
       " ('fluorescents', 5),\n",
       " ('explanation', 5),\n",
       " ('lidocaine', 5),\n",
       " ('company', 5),\n",
       " ('name', 5),\n",
       " ('filter', 5),\n",
       " ('postdrome', 5),\n",
       " ('scalp', 5),\n",
       " ('doc', 5),\n",
       " ('dilation', 5),\n",
       " ('stores', 5),\n",
       " ('boss', 5),\n",
       " ('idk', 5),\n",
       " ('sport', 5),\n",
       " ('touch', 5),\n",
       " ('psychiatrist', 5),\n",
       " ('pleasure', 5),\n",
       " ('errands', 5),\n",
       " ...]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counted_triggers = Counter(unfiltered_triggers)\n",
    "most_frequent = sorted(counted_triggers.items(), key=lambda k: k[1], reverse=True)\n",
    "most_frequent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4367"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(counted_triggers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at this list we can clearly see that anything with frequency below 90 is just noise.  And even in the most frequent list there are some words that are clearly not triggers.  So let's keep only the triggers with frequency above 90."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_frequent_and_useful = [entry for entry in most_frequent if entry[1] > 90]\n",
    "len(most_frequent_and_useful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('migraines', 3826),\n",
       " ('migraine', 3093),\n",
       " ('triggers', 653),\n",
       " ('pain', 510),\n",
       " ('stress', 505),\n",
       " ('foods', 466),\n",
       " ('things', 464),\n",
       " ('headaches', 460),\n",
       " ('lot', 441),\n",
       " ('attack', 407),\n",
       " ('headache', 389),\n",
       " ('changes', 388),\n",
       " ('symptoms', 381),\n",
       " ('lights', 318),\n",
       " ('alcohol', 314),\n",
       " ('sleep', 270),\n",
       " ('food', 267),\n",
       " ('caffeine', 258),\n",
       " ('attacks', 257),\n",
       " ('diet', 248),\n",
       " ('injections', 244),\n",
       " ('weather', 232),\n",
       " ('pressure', 229),\n",
       " ('diary', 220),\n",
       " ('time', 217),\n",
       " ('chocolate', 210),\n",
       " ('anxiety', 208),\n",
       " ('patterns', 201),\n",
       " ('sugar', 199),\n",
       " ('dehydration', 198),\n",
       " ('light', 188),\n",
       " ('trigger', 188),\n",
       " ('issues', 172),\n",
       " ('neck', 164),\n",
       " ('hormones', 158),\n",
       " ('exercise', 157),\n",
       " ('idea', 149),\n",
       " ('meds', 149),\n",
       " ('wine', 140),\n",
       " ('water', 137),\n",
       " ('lack', 133),\n",
       " ('information', 129),\n",
       " ('days', 125),\n",
       " ('coffee', 124),\n",
       " ('head', 121),\n",
       " ('meals', 120),\n",
       " ('cheese', 113),\n",
       " ('journal', 112),\n",
       " ('list', 112),\n",
       " ('points', 108),\n",
       " ('tension', 108),\n",
       " ('one', 103),\n",
       " ('heat', 102),\n",
       " ('medication', 101),\n",
       " ('people', 100),\n",
       " ('sense', 99),\n",
       " ('relief', 99),\n",
       " ('others', 98),\n",
       " ('thing', 97),\n",
       " ('lots', 96),\n",
       " ('ones', 96),\n",
       " ('nausea', 95),\n",
       " ('severity', 91),\n",
       " ('life', 91),\n",
       " ('track', 91)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_frequent_and_useful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This number is reasonable to manually prune and remove incorrect entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_entries = set([\n",
    "    'migraines',\n",
    "    'migraine',\n",
    "    'triggers',\n",
    "    'things',\n",
    "    'headaches',\n",
    "    'lot',\n",
    "    'attack',\n",
    "    'headache',\n",
    "    'changes',\n",
    "    'symptoms',\n",
    "    'food',\n",
    "    'attacks',\n",
    "    'diet',\n",
    "    'injections',\n",
    "    'diary',\n",
    "    'time',\n",
    "    'patterns',\n",
    "    'trigger',\n",
    "    'issues',\n",
    "    'neck',\n",
    "    'idea',\n",
    "    'lack',\n",
    "    'information',\n",
    "    'days',\n",
    "    'head',\n",
    "    'meals',\n",
    "    'journal',\n",
    "    'list',\n",
    "    'points',\n",
    "    'one',\n",
    "    'people',\n",
    "    'sense',\n",
    "    'relief',\n",
    "    'others',\n",
    "    'thing',\n",
    "    'lots',\n",
    "    'ones',\n",
    "    'severity',\n",
    "    'life',\n",
    "    'track'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alcohol',\n",
       " 'anxiety',\n",
       " 'caffeine',\n",
       " 'cheese',\n",
       " 'chocolate',\n",
       " 'coffee',\n",
       " 'dehydration',\n",
       " 'exercise',\n",
       " 'foods',\n",
       " 'heat',\n",
       " 'hormones',\n",
       " 'light',\n",
       " 'lights',\n",
       " 'medication',\n",
       " 'meds',\n",
       " 'nausea',\n",
       " 'pain',\n",
       " 'pressure',\n",
       " 'sleep',\n",
       " 'stress',\n",
       " 'sugar',\n",
       " 'tension',\n",
       " 'water',\n",
       " 'weather',\n",
       " 'wine'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "migraine_triggers = set([entry[0] for entry in most_frequent_and_useful if entry[0] not in bad_entries])\n",
    "migraine_triggers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create index of triggers per author!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_triggers_in_posts(nlp):\n",
    "    def process(idx):\n",
    "        trigger_idx = copy.deepcopy(idx)\n",
    "        pattern = re.compile('(trigger|triggers)', re.IGNORECASE)\n",
    "\n",
    "        def normalize_triggers(word):\n",
    "            if word == 'pressure':\n",
    "                return 'barometric pressure'\n",
    "            if word == 'water':\n",
    "                return 'dehydration'\n",
    "            if word == 'meds':\n",
    "                return 'medication'\n",
    "            return word\n",
    "\n",
    "        def find_triggers_in_text(text):\n",
    "            triggers = []\n",
    "            doc = nlp(text)\n",
    "            dep_type = None\n",
    "            for token in doc:\n",
    "                if (token.dep_ == 'nsubj' or token.dep_ == 'dobj' or token.dep_ == 'pobj') \\\n",
    "                    and pattern.search(token.text):\n",
    "                    dep_type = token.dep_\n",
    "                if token.pos_ == 'NOUN' and token.dep_ != dep_type and (token.dep_ == 'punc' or token.dep_ == 'dobj' or token.dep_ == 'conj'):\n",
    "                    if token.text in migraine_triggers:\n",
    "                        triggers.append(\n",
    "                            normalize_triggers(token.text)\n",
    "                        )\n",
    "            return triggers\n",
    "\n",
    "        def process_entry(author, text):\n",
    "            triggers = []\n",
    "            if pattern.search(text) is None:\n",
    "                trigger_idx[author]['triggers'] = triggers\n",
    "                return\n",
    "            for sentence in sentences_with_triggers(text):\n",
    "                triggers.extend(find_triggers_in_text(sentence))\n",
    "            trigger_idx[author]['triggers'] = triggers\n",
    "\n",
    "        def sentences_with_triggers(text):\n",
    "            doc = nlp(text)\n",
    "            sentences = [str(sent) for sent in doc.sents if pattern.search(str(sent))]\n",
    "            return sentences\n",
    "\n",
    "        for author, text in posts_and_commnets:\n",
    "            process_entry(author, text)\n",
    "        return trigger_idx\n",
    "    return process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "identify_authors_triggers_in_posts = find_triggers_in_posts(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46918"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_index = identify_authors_triggers_in_posts(author_index)\n",
    "len(author_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total authors with identifiable triggers 627\n"
     ]
    }
   ],
   "source": [
    "total_with_triggers = 0\n",
    "\n",
    "for _, v in author_index.items():\n",
    "    if len(v['triggers']):\n",
    "        total_with_triggers += 1\n",
    "\n",
    "print(f'Total authors with identifiable triggers {total_with_triggers}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature - Author's Who Experience Aura\n",
    "\n",
    "Start by finding all articles that refer to aura and then get random sample to find sentences and determine patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15778"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auro_pattern = re.compile('(aura)', re.IGNORECASE)\n",
    "\n",
    "aura_posts = []\n",
    "for entry in posts_and_commnets:\n",
    "    text = entry[1]\n",
    "    if auro_pattern.search(text):\n",
    "        aura_posts.append(text)\n",
    "\n",
    "len(aura_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mine started a little before then, I was having extremely painful migraines with the aura, headache; the throwing up. It always came before my period.\n",
      "---------------------------------\n",
      "I want to start out by saying that I’m very familiar with migraines, ocular ones specially. Once every few months I get the visual aura, limbs and face falling asleep, and confusion that comes with these types of migraines, and then usually get the headache that follows, but not always.\n",
      "\n",
      "The last three days I’ve had a headache in the back of my head that doesn’t go away unless I take Advil, and a constant nausea that’s more in my head/throat than in my stomach. I don’t think I have a stomach bug or ate anything bad because I still get hungry and can eat just fine, there’s just a constant weird nauseous feeling in the bottom of my throat.\n",
      "\n",
      "Anyway, can this nausea be a migraine? I’m just so used to the visual type of migraines that this seems weird to me. Does anyone else experience this? Any remedies you suggest?\n",
      "\n",
      "Thank you in advance!\n",
      "---------------------------------\n",
      "Yeah. Shes alright. Just happened in middle school so i had no idea what it was and just figured my aura was me having one too. The whole school was on edge following that incident. \n",
      "---------------------------------\n",
      "Yes, from time to time. Oddly enough, the very first time I experienced aura (I was 7 or 8) it was static or tv “snow” in my vision with that exact sensation behind my forehead. I remember it vividly because it scared the crap out of me and I basically had meltdown sitting at the kitchen table. My parents were very concerned and confused. \n",
      "\n",
      "For me, it passes pretty quickly. My only suggestion is to maybe try applying a cold pack, or heat, if that’s your helper temperature, to see if it can proved some comfort.\n",
      "---------------------------------\n",
      "Same. I get this as an aura. I can’t finish sentences I’ve started. I can’t think of words. I also get it in the postdrome (it’s happening right now...lol)...phase of my migraines. I always say my migraines make me stupid.\n",
      "---------------------------------\n",
      "Sure. I am always fatigued. I have probably 28 migraines a month or more. Sometimes with aura. I get dizzy. I have a hard time sleeping and a hard time getting up. I have a lot of pressure in my forehead and eyebrows and I get ice pick migraines a few times a week. Aleve doesn’t usually work nor does triptans. I can do a few things between 9am and 2 pm and then I hit a wall and rest until about dinner but I’m pretty worthless after 2. If I’m busy a few days in a row I will inevitably end up in bed for a day. I have other health issues. I see floaters and lines. Barometric pressure is not my friend. I feel my best migraine wise late at night. I have had this since last year in March. \n",
      "---------------------------------\n",
      "Same, exactly. And if it's all bullshit and there's no science behind it, but I feel better - COOOL, I got a pretty piercing and I feel better! \n",
      "\n",
      "Took me a while to figure out my aura, it's not nearly as pronounced as most are. I hate to say it, but it might take a few more episodes to really figure it out. Just watch for anything that feels *different* - even something as simple as being more emotional than usual, or your ears getting red and hot (its a thing).  \n",
      "Best of luck to you, and hang in there!\n",
      "\n",
      "---------------------------------\n",
      "I have hemiplegic migraine. I have suffered with migraine since I was a child, however the hemiplegia didn't begin until I was in my teens. You can get numbness as part of aura but the key thing that makes numbness part of a hemiplegic migraine is a lasting weakness in the affected numb areas. It usually begins the same way: a wave of numbness starts in my finger tips, travels slowly up my arm to my shoulder, onto my face and spreading out from there. My mouth droops and i dribble. I get numb patches on my back and thighs too, before it dissipates. I find that my fine motor skills, particularly my arms, are affected for the length of the postdrome or \"hangover\", which for me is a few days. I have no issues that have lasted longer than that. I hope you are feeling better.\n",
      "---------------------------------\n",
      "38m here.  I get them since puberty. Only had visual issue once. My mom gets the painful migraine  my dad gets the aura with no pain.\n",
      "---------------------------------\n",
      "That sounds normal for migraine. But it also sucks a lot, so talk to your doctor about meds you can take during the aura that will hopefully make it less bad.\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "# We used larger samples of 100 but changed to 10 so the notebook\n",
    "# doesn't get to large\n",
    "aura_samples = random.sample(aura_posts, 10)\n",
    "\n",
    "for sample in aura_samples:\n",
    "    print(sample)\n",
    "    print('---------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the above input we get following sample sentences that we can base regex patterns from:\n",
    "\n",
    "- my aura started\n",
    "- to the first aura\n",
    "- migraines with aura\n",
    "- I start seeing auras\n",
    "- I’ve been experiencing migraine with aura\n",
    "- during my auras\n",
    "- I do have aura\n",
    "- My auras vision is permanent\n",
    "- I get visual auras\n",
    "- This morning during the aura\n",
    "- I notice the aura\n",
    "- the aura tells me\n",
    "- I used to get auras\n",
    "- My early stage aura\n",
    "- When I get auras\n",
    "- I had an aura\n",
    "- I get a visual aura\n",
    "\n",
    "So there are couple patterns here but the most common one is `I <some words> aura(s)`.  However, with this pattern we need to watch out for\n",
    "negations, specifically, following patterns:\n",
    "\n",
    "- I don't have aura\n",
    "- I do not have aura\n",
    "- I am without aura\n",
    "- I am w/o aura\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_aura_sentences = [\n",
    "    \"my aura started\",\n",
    "    \"to the first aura\",\n",
    "    \"migraines with aura\",\n",
    "    \"I start seeing auras\",\n",
    "    \"I’ve been experiencing migraine with aura\",\n",
    "    \"during my auras\",\n",
    "    \"I do have aura\",\n",
    "    \"My auras vision is permanent\",\n",
    "    \"I get visual auras\",\n",
    "    \"This morning during the aura\",\n",
    "    \"I notice the aura\",\n",
    "    \"the aura tells me\",\n",
    "    \"I used to get auras\",\n",
    "    \"My early stage aura\",\n",
    "    \"When I get auras\",\n",
    "    \"I had an aura\",\n",
    "    \"I get a visual aura\"\n",
    "]\n",
    "\n",
    "negative_aura_sentences = [\n",
    "    \"I don't have aura\",\n",
    "    \"I do not have aura\",\n",
    "    \"I am without aura\",\n",
    "    \"I am w/o aura\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_aura_matchers = [\n",
    "    re.compile('(i|my).*(aura|auras)', re.IGNORECASE),\n",
    "    re.compile('(with|first).*(aura|auras)', re.IGNORECASE),\n",
    "    re.compile('(aura|auras).*(me)', re.IGNORECASE)\n",
    "]\n",
    "\n",
    "negative_aura_matchers = [\n",
    "    re.compile('(i|my).*(\\snot\\s|without).*(aura|auras)', re.IGNORECASE),\n",
    "    re.compile(\"(i|my).*(don't|w/o).*(aura|auras)\", re.IGNORECASE)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_for_auras(text):\n",
    "    return any([matcher.search(text) for matcher in positive_aura_matchers]) \\\n",
    "        and not any([matcher.search(text) for matcher in negative_aura_matchers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_age_matchers (__main__.TestAgeDiscovery) ... ok\n",
      "test_aura_matchers (__main__.TestAuraDiscovery) ... ok\n",
      "test_female_matchers (__main__.TestGenderDiscovery) ... ok\n",
      "test_male_matchers (__main__.TestGenderDiscovery) ... ok\n",
      "test_dosage_matchers (__main__.TestMedicineDosageDiscovery) ... ok\n",
      "test_suicidal_matchers (__main__.TestSuicidalThoughtsDiscovery) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 0.010s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "# Unit tests\n",
    "class TestAuraDiscovery(unittest.TestCase):\n",
    "    def test_aura_matchers(self):\n",
    "        self.assertTrue(all([search_for_auras(text) for text in positive_aura_sentences]))\n",
    "        self.assertFalse(all([search_for_auras(text) for text in negative_aura_sentences]))\n",
    "\n",
    "res = unittest.main(argv=[''], verbosity=3, exit=False)\n",
    "assert len(res.result.failures) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create author to aura index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_authors_aura_in_posts(idx):\n",
    "    aura_idx = copy.deepcopy(idx)\n",
    "    def process_entry(author, text):\n",
    "        aura_idx[author]['aura'] = str(bool(search_for_auras(text))).lower()\n",
    "\n",
    "    for author, text in posts_and_commnets:\n",
    "        process_entry(author, text)\n",
    "    return aura_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46918"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_index = identify_authors_aura_in_posts(author_index)\n",
    "len(author_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total authors with aura 2370\n"
     ]
    }
   ],
   "source": [
    "total_authors_with_aura = 0\n",
    "\n",
    "for _, v in author_index.items():\n",
    "    if v['aura'] == 'true':\n",
    "        total_authors_with_aura += 1\n",
    "\n",
    "print(f'Total authors with aura {total_authors_with_aura}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature - Authors with ADHD\n",
    "\n",
    "This has similar approach as Aura detection.  Find texts with ADHD in it and sample to gather sentences describing ADHD and build regex based on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "720"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adhd_pattern = re.compile('(ADHD)', re.IGNORECASE)\n",
    "\n",
    "adhd_posts = []\n",
    "for entry in posts_and_commnets:\n",
    "    text = entry[1]\n",
    "    if adhd_pattern.search(text):\n",
    "        adhd_posts.append(text)\n",
    "\n",
    "len(adhd_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes! ADHD medications are stimulants, and stimulants can make migraines worse. So anything like caffeine, nicotine, or even prescription drugs are not very good for migraines.\n",
      "\n",
      "I was just diagnosed with ADHD in April, so I'm not super missing out on the meds for it, I've had to learn to cope without my whole life (I'm 25). I have a little caffeine every day, and have for years, because I have issues focusing without. This is basically me self medicating my ADHD without realizing it. Keeping how much caffeine I have every day as low as possible did help my migraines, but cutting it out completely didn't help further, so I've managed to find a good balance that my doctor's approve of.\n",
      "\n",
      "Just have a conversation with your doctor! They might suggest lowering your dose a bit to see if that helps with migraines. But if your migraines got worse after birth control, they might be triggered by hormones (mine are). Every person is different, and unfortunately it takes some trial and error to figure out what works best for you.\n",
      "\n",
      "I hope this answered your question! I had a migraine last night so my brain is extra scrambled today, so I'm willing to clarify if needed :)\n",
      "---------------------------------\n",
      "So I took a trip to Hawaii in January. The day of my flight home went snorkling on a boat excursion during the day and flew red eye home (6 hours over the pacific) and then a small domestic flight. I was a swimmer when I was younger and can hold my breath quite awhile so I can swim pretty deep and I did that day. \n",
      "\n",
      "Before my flight I took an adderall (prescribed and diagnosed with adhd) since I cannot sleep on flights so I decided I would just read a book. \n",
      "\n",
      "I also cried a ton in the airport saying goodbye to my sister who lives in a different city than me so lots of pressure in my eyes and head from that and then I got on another domestic flight. \n",
      "\n",
      "After a few day’s back at work my lower eye lid on my left eye started twitching and the lights all felt really bright. I was doing a lot of overtime to catch up so on screen for 10 hours a day for a few weeks. \n",
      "\n",
      "More visual symptoms started and I had to stop work. Still experiencing “migraines” or silent migraines as some have called it at least every 2nd day since that trip. \n",
      "\n",
      "Did the combo of swimming deep, then flying and maybe my prescription, plus overtime and lack of sleep flying red eye send me into a life long battle with migraines? I just can’t understand how I’ve never had issues and then all of a sudden bam. Still unable to go back to work or use a computer. I recently flew domestically to see my sister and I’m having headaches and blood vessel twitching in my temples and eyes like how it started last time every day while I’m here. This makes me think that altitude triggered them. \n",
      "\n",
      "Thoughts? \n",
      "\n",
      "SS: did altitude and other external stimuli trigger my chronic migraines to present?\n",
      "---------------------------------\n",
      "Interesting, have wondered about this link before. Vyvanse is my miracle, turned-me-into-a-functional-human ADHD drug (I take 50 mg), but I've suspected it of triggering migraine flares occasionally. Tough to tell since the migraines are chronic and  there are a million other factors at play. \n",
      "---------------------------------\n",
      "It is number 1 in New release when I just added to my cart. \n",
      "\n",
      "Now I need something like this to track my adhd symptoms.\n",
      "---------------------------------\n",
      "Fuck them, you are much better off without that level of selfishness in your life, I'm 38 I've migraines and adhd, i have one mate he lives up in dublin which is the guts of an hour up the road I see him maybe three times a year and the dude is my best mate, if I bail on him or him on me for whatever reason at all neither of us gets pissed off about it, friends don't make your problems all about them and if they do they're not your friend. Join a club/group for something your into and interact with people there, you'll find like minded people who aren't selfish. I hope you find a nice friend soon.\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "adhd_samples = random.sample(adhd_posts, 5)\n",
    "\n",
    "for sample in adhd_samples:\n",
    "    print(sample)\n",
    "    print('---------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the list of the picked sample sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_adhd_sentences = [\n",
    "    \"I struggle with ADHD\",\n",
    "    \"I have ADHD\",\n",
    "    \"I was diagnosed with ADHD\",\n",
    "    \"ADHD here\",\n",
    "    \"treating ADHD\",\n",
    "    \"I was already struggling with ADHD\",\n",
    "    \"I’ve got ADHD\",\n",
    "    \"I have adhd\",\n",
    "    \"prescription for ADHD medication\",\n",
    "    \"because my ADHD meds\",\n",
    "    \"I have adhd and asd\",\n",
    "    \"I take ADHD meds\",\n",
    "    \"you can take charge of the ADHd\",\n",
    "    \"my ADHD makes\",\n",
    "    \"diagnosed with ADHD\",\n",
    "    \"I have ADHD\"\n",
    "]\n",
    "\n",
    "negative_adhd_sentences = [\n",
    "    \"I have asd\",\n",
    "    \"I ride a bike\",\n",
    "    \"I don't have ADHD\",\n",
    "    \"I've got no ADHD\",\n",
    "    \"I do not have ADHD\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_adhd_matchers = [\n",
    "    re.compile('(i|my).*(adhd)', re.IGNORECASE),\n",
    "    re.compile('(take|treat|treating|diagnosed|prescription).*(adhd)', re.IGNORECASE),\n",
    "    re.compile('(adhd).*(here)', re.IGNORECASE)\n",
    "]\n",
    "\n",
    "negative_adhd_matchers = [\n",
    "    re.compile('(i|my).*(\\snot\\s|without).*(aura|auras)', re.IGNORECASE),\n",
    "    re.compile(\"(i|my).*(don't|\\sno\\s).*(aura|auras)\", re.IGNORECASE)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_for_adhd(text):\n",
    "    return any([matcher.search(text) for matcher in positive_adhd_matchers]) \\\n",
    "        and not any([matcher.search(text) for matcher in negative_adhd_matchers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_adhd_matchers (__main__.TestAdhdDiscovery) ... ok\n",
      "test_age_matchers (__main__.TestAgeDiscovery) ... ok\n",
      "test_aura_matchers (__main__.TestAuraDiscovery) ... ok\n",
      "test_female_matchers (__main__.TestGenderDiscovery) ... ok\n",
      "test_male_matchers (__main__.TestGenderDiscovery) ... ok\n",
      "test_dosage_matchers (__main__.TestMedicineDosageDiscovery) ... ok\n",
      "test_suicidal_matchers (__main__.TestSuicidalThoughtsDiscovery) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 7 tests in 0.012s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "# Unit tests\n",
    "class TestAdhdDiscovery(unittest.TestCase):\n",
    "    def test_adhd_matchers(self):\n",
    "        self.assertTrue(all([search_for_adhd(text) for text in positive_adhd_sentences]))\n",
    "        self.assertFalse(all([search_for_adhd(text) for text in negative_adhd_sentences]))\n",
    "\n",
    "res = unittest.main(argv=[''], verbosity=3, exit=False)\n",
    "assert len(res.result.failures) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_authors_adhd_in_posts(idx):\n",
    "    adhd_idx = copy.deepcopy(idx)\n",
    "    def process_entry(author, text):\n",
    "        adhd_idx[author]['adhd'] = str(bool(search_for_adhd(text))).lower()\n",
    "\n",
    "    for author, text in posts_and_commnets:\n",
    "        process_entry(author, text)\n",
    "    return adhd_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46918"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_index = identify_authors_adhd_in_posts(author_index)\n",
    "len(author_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total authors with ADHD 92\n"
     ]
    }
   ],
   "source": [
    "total_authors_with_adhd = 0\n",
    "\n",
    "for _, v in author_index.items():\n",
    "    if v['adhd'] == 'true':\n",
    "        total_authors_with_adhd += 1\n",
    "\n",
    "print(f'Total authors with ADHD {total_authors_with_adhd}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Features Counts\n",
    "\n",
    "Now we want to check how many authors we have that have at least one feature.  We really want to get rid of any author that we could not identify any features for as there is no value to that entry.\n",
    "\n",
    "In addition, it's interesting to know how many authors have all of the features.\n",
    "\n",
    "First let's define some helper functions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features like suicidal, ADHD, aura are set for all of the authors\n",
    "# so we ignore those \n",
    "def has_features(entry):\n",
    "    if entry['age'] == 0 and \\\n",
    "       len(entry['triggers']) == 0 and \\\n",
    "       entry['medicine'] == 'unknown' and \\\n",
    "       entry['gender'] == 'unknown':\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def has_all_features(entry):\n",
    "    if entry['age'] != 0 and \\\n",
    "       len(entry['triggers']) != 0 and \\\n",
    "       entry['medicine'] != 'unknown' and \\\n",
    "       entry['gender'] != 'unknown':\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authors with at least one feature: 4298\n",
      "Authors with all features: 3\n"
     ]
    }
   ],
   "source": [
    "# Count at least one and all features\n",
    "total_at_least_one = 0\n",
    "total_all = 0\n",
    "\n",
    "for author, entry in author_index.items():\n",
    "    if has_features(entry):\n",
    "        total_at_least_one += 1\n",
    "    if has_all_features(entry):\n",
    "        total_all += 1\n",
    "\n",
    "print(f'Authors with at least one feature: {total_at_least_one}')\n",
    "print(f'Authors with all features: {total_all}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the  Dataset\n",
    "\n",
    "Our dataset will take all the author entries that have at least one feature and create a CSV file to store it.\n",
    "\n",
    "However, to ensure author's privacy we need to replace author's user IDs with some unique identifier. We decided to simply replace author's Reddis and Migraine.com userid with UUID.  This allows us to still have unique id for each author without giving away their Reddis or Migraine.com userid.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "for _, entry in author_index.items():\n",
    "    entry['id'] = uuid.uuid4()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4298"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list = [entry for _, entry in author_index.items() if has_features(entry)]\n",
    "output_df = pd.DataFrame(data=data_list)\n",
    "len(output_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>medicine</th>\n",
       "      <th>dosage</th>\n",
       "      <th>qty</th>\n",
       "      <th>suicidal</th>\n",
       "      <th>age</th>\n",
       "      <th>triggers</th>\n",
       "      <th>aura</th>\n",
       "      <th>adhd</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>[pain]</td>\n",
       "      <td>false</td>\n",
       "      <td>false</td>\n",
       "      <td>f943925d-e66b-4ecf-8cd0-0df7dd0a4ec6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>[stress]</td>\n",
       "      <td>false</td>\n",
       "      <td>false</td>\n",
       "      <td>343502cc-db1f-4aa0-b761-822297f47c1d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>[caffeine, chocolate, lights, lights, alcohol,...</td>\n",
       "      <td>false</td>\n",
       "      <td>false</td>\n",
       "      <td>e577e633-d3e5-4bd2-b5c6-cb1488062a5f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>unknown</td>\n",
       "      <td>triptan</td>\n",
       "      <td>40mg</td>\n",
       "      <td>1x</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>false</td>\n",
       "      <td>false</td>\n",
       "      <td>f0587974-3841-4e9b-853a-b34fcd03eabf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>[sleep]</td>\n",
       "      <td>false</td>\n",
       "      <td>false</td>\n",
       "      <td>d6b642cf-8dfd-481d-b568-5aee7f8c056e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender medicine   dosage      qty suicidal  age  \\\n",
       "195  unknown  unknown  unknown  unknown       no    0   \n",
       "196  unknown  unknown  unknown  unknown       no    0   \n",
       "197  unknown  unknown  unknown  unknown       no    0   \n",
       "198  unknown  triptan     40mg       1x       no    0   \n",
       "199  unknown  unknown  unknown  unknown       no    0   \n",
       "\n",
       "                                              triggers   aura   adhd  \\\n",
       "195                                             [pain]  false  false   \n",
       "196                                           [stress]  false  false   \n",
       "197  [caffeine, chocolate, lights, lights, alcohol,...  false  false   \n",
       "198                                                 []  false  false   \n",
       "199                                            [sleep]  false  false   \n",
       "\n",
       "                                       id  \n",
       "195  f943925d-e66b-4ecf-8cd0-0df7dd0a4ec6  \n",
       "196  343502cc-db1f-4aa0-b761-822297f47c1d  \n",
       "197  e577e633-d3e5-4bd2-b5c6-cb1488062a5f  \n",
       "198  f0587974-3841-4e9b-853a-b34fcd03eabf  \n",
       "199  d6b642cf-8dfd-481d-b568-5aee7f8c056e  "
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df[195:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dataset_filename = 'migraine_all.csv'\n",
    "output_df.to_csv(f'data/{output_dataset_filename}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "043ded0200596b90969cdaf78db8cc3255494a426d99ef977fa69e36f146e9e2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit ('migraine-data-reddit-WM5Df_6q-py3.9': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
