{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "\n",
    "The purpose of this notebook is to show how and the process of extracting each feature form texts of posts in Reddis and migraine.com\n",
    "\n",
    "Based on the work done for the [project proposal](./group_11_proposal.ipynb) we identified following features to extract:\n",
    "\n",
    "- Age\n",
    "- Gender\n",
    "- Medicine use and dosage\n",
    "- Suicidal thoughts\n",
    "- Migraine triggers\n",
    "- Presence of aura\n",
    "- Trouble with sleeping\n",
    "- ADHD\n",
    "\n",
    "In the rest of this notebook we show the process of getting each feature out and constructing the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import unittest\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddis_data_filename = 'reddis_migraine_posts.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_reddis_data(filename):\n",
    "    df = pd.read_csv(f'data/{filename}', header=0)\n",
    "    df = df.dropna(subset=['Text'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_and_commnets = read_reddis_data(reddis_data_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Parent</th>\n",
       "      <th>Author</th>\n",
       "      <th>Text</th>\n",
       "      <th>Title</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Webpage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P</td>\n",
       "      <td>q1pdf8</td>\n",
       "      <td>Conscious_Escape_408</td>\n",
       "      <td>I've been awake the entire night with the wors...</td>\n",
       "      <td>Worst I've ever had/calling in sick</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P</td>\n",
       "      <td>q1p2lt</td>\n",
       "      <td>Sia-King</td>\n",
       "      <td>Hey y’all, I got a referral for a neurologist ...</td>\n",
       "      <td>What preventative to trial next? (Asthmatic &amp;a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P</td>\n",
       "      <td>q1otox</td>\n",
       "      <td>netluv</td>\n",
       "      <td>It’s day two night two of a migraine. I’ve max...</td>\n",
       "      <td>Pain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P</td>\n",
       "      <td>q1odf7</td>\n",
       "      <td>Dazee80</td>\n",
       "      <td>I am in a fucked position. I have had migraine...</td>\n",
       "      <td>Pain vs Relationship</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>P</td>\n",
       "      <td>q1kv1i</td>\n",
       "      <td>doitforthepizza</td>\n",
       "      <td>Hi everyone, I'm new here (44f). First I'll sa...</td>\n",
       "      <td>New to this and wondering if others experience...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Type  Parent                Author  \\\n",
       "0    P  q1pdf8  Conscious_Escape_408   \n",
       "1    P  q1p2lt              Sia-King   \n",
       "2    P  q1otox                netluv   \n",
       "3    P  q1odf7               Dazee80   \n",
       "5    P  q1kv1i       doitforthepizza   \n",
       "\n",
       "                                                Text  \\\n",
       "0  I've been awake the entire night with the wors...   \n",
       "1  Hey y’all, I got a referral for a neurologist ...   \n",
       "2  It’s day two night two of a migraine. I’ve max...   \n",
       "3  I am in a fucked position. I have had migraine...   \n",
       "5  Hi everyone, I'm new here (44f). First I'll sa...   \n",
       "\n",
       "                                               Title  Tags  Webpage  \n",
       "0                Worst I've ever had/calling in sick   NaN      NaN  \n",
       "1  What preventative to trial next? (Asthmatic &a...   NaN      NaN  \n",
       "2                                               Pain   NaN      NaN  \n",
       "3                               Pain vs Relationship   NaN      NaN  \n",
       "5  New to this and wondering if others experience...   NaN      NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_and_commnets[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction Approach\n",
    "\n",
    "Different features needed somewhat different approach to retrieving them from the posts and comments.  However, there is general workflow that we used for working on all of the features.  \n",
    "\n",
    "The nature of the data is that authors write in multiple posts and comments.  The main goal is to scan through these posts and identify features for each author.  Different features can come from author's different posts.  For example, in one post author can be speaking about something that identifies their gender and in another post about something that identifies their age.\n",
    "\n",
    "To capture all the features we create index where author is the key and value is a dictionary of the features.\n",
    "\n",
    "Workflow:\n",
    "\n",
    "- Find sentences that describe feature we are looking for.  We do this by first identifying some keyword and filtering posts by that keyword and than taking random sample from that list.\n",
    "- Once the list of sample sentences that represent feature is created, we build set of regex expression to identify all of the language patterns that the feature can be expressed with.\n",
    "- With both sample sentences and regex expressions we build function that can identify the feature given text.  To ensure that the function works correctly we create unittest and use sample sentences as input for the unittest.  This saves us time from debugging later on large dataset.\n",
    "- Finally, we run feature extracting function again entire dataset and update author index with found features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up Author Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "author_index = defaultdict(dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine Number of Unique Authors\n",
    "\n",
    "Checking number of unique authors in the dataset. This will be maximum possible number of entries for our resulting dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total posts and comments: 387535\n",
      "Unique authors: 41209\n"
     ]
    }
   ],
   "source": [
    "print(f'Total posts and comments: {len(posts_and_commnets)}')\n",
    "print(f'Unique authors: {len(set(posts_and_commnets[\"Author\"]))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature - Discover Gender\n",
    "\n",
    "For Reddis authors we must extract information on author's gender from the posts themselves as userids are auto generated by Reddis so there is very little chance that someone would change it to their names.\n",
    "\n",
    "In order to figure out how to do it we looked through posts and looked for examples of how people either identify themselves or if they say something that would help us to identify their gender, for example, \"Me and my husband.\"\n",
    "\n",
    "We found following sentences that we used to retrieve regex patterns from:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_male_sentences = [\n",
    "    \"I am married and my Wife and I....\",\n",
    "    \"Me and my girlfriend went somewhere\",\n",
    "    \"Hello, me 44m and have migraines\",\n",
    "    \"Hello, me 44(m) and have migraines\",\n",
    "    \"Hello, me 44 (M) and have migraines\",\n",
    "    \"Hello, me 44 male and have migraines\",\n",
    "    \"Hello, I am male 44 and have migraines\"\n",
    "]\n",
    "\n",
    "sample_female_sentences = [\n",
    "    \"Me and my husband have a car.\",\n",
    "    \"Something I am currently pregnant and so on\",\n",
    "    \"Something I am pregnant and so on\",\n",
    "    \"Something I'm pregnant and so on\",\n",
    "    \"I have had menstruation related migraine\",\n",
    "    \"Me and my boyfriend went somewhere\",\n",
    "    \"Hello, me 44f and have migraines\",\n",
    "    \"Hello, me 44(f) and have migraines\",\n",
    "    \"Hello, me 44 (F) and have migraines\",\n",
    "    \"Hello, me 44 female and have migraines\",\n",
    "    \"Hello, I am female 44 and have migraines\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex patterns\n",
    "male_matchers = [\n",
    "    re.compile('my\\s+wife', re.IGNORECASE),\n",
    "    re.compile('my\\s.*girlfriend', re.IGNORECASE),\n",
    "    re.compile('\\s[0-9][0-9](m\\s|\\(m\\)|\\s\\(m\\))', re.IGNORECASE),\n",
    "    re.compile('\\s[0-9][0-9].*male', re.IGNORECASE),\n",
    "    re.compile('male.*[0-9][0-9]', re.IGNORECASE)\n",
    "]\n",
    "\n",
    "female_matchers = [\n",
    "    re.compile('my\\s+husband', re.IGNORECASE),\n",
    "    re.compile('I( am|\\'m)\\s.*pregnant', re.IGNORECASE),\n",
    "    re.compile('I\\s.*menstruation', re.IGNORECASE),\n",
    "    re.compile('my\\s.*boyfriend', re.IGNORECASE),\n",
    "    re.compile('\\s[0-9][0-9](f|\\(f\\)|\\s\\(f\\))', re.IGNORECASE),\n",
    "    re.compile('\\s[0-9][0-9].*female', re.IGNORECASE),\n",
    "    re.compile('female.*[0-9][0-9]', re.IGNORECASE)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender discovery functions\n",
    "def discover_gender(matchers):\n",
    "    def find_in_text(text):\n",
    "        return any([\n",
    "            matcher.search(text) for matcher in matchers\n",
    "        ])\n",
    "    return find_in_text\n",
    "\n",
    "find_females = discover_gender(female_matchers)\n",
    "find_males = discover_gender(male_matchers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_female_matchers (__main__.TestGenderDiscovery) ... ok\n",
      "test_male_matchers (__main__.TestGenderDiscovery) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.002s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "# Unit tests\n",
    "class TestGenderDiscovery(unittest.TestCase):\n",
    "    def test_male_matchers(self):\n",
    "        self.assertTrue(all([find_males(text) for text in sample_male_sentences]))\n",
    "        self.assertFalse(all([find_males(text) for text in sample_female_sentences]))\n",
    "\n",
    "    def test_female_matchers(self):\n",
    "        self.assertTrue(all([find_females(text) for text in sample_female_sentences]))\n",
    "        self.assertFalse(all([find_females(text) for text in sample_male_sentences]))\n",
    "\n",
    "res = unittest.main(argv=[''], verbosity=3, exit=False)\n",
    "assert len(res.result.failures) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_gender(text):\n",
    "    if find_males(text):\n",
    "        return 'male'\n",
    "    elif find_females(text):\n",
    "        return 'female'\n",
    "    return 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_gender_in_posts(idx):\n",
    "    gender_idx = copy.deepcopy(idx)\n",
    "    def process_entry(author, text):\n",
    "        gender_idx[author] = {'gender': identify_gender(text)}\n",
    "\n",
    "    posts_and_commnets.apply(lambda x: process_entry(x['Author'], x['Text']), axis=1)\n",
    "    return gender_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41209"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_index = identify_gender_in_posts(author_index)\n",
    "len(author_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count how many authors were identified as male or female or unknown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male: 634, female: 631, unknown: 39944\n"
     ]
    }
   ],
   "source": [
    "count_m = 0\n",
    "count_f = 0\n",
    "count_u = 0\n",
    "\n",
    "for _, v in author_index.items():\n",
    "    if v['gender'] == 'male':\n",
    "        count_m += 1\n",
    "    if v['gender'] == 'female':\n",
    "        count_f += 1\n",
    "    if v['gender'] == 'unknown':\n",
    "        count_u += 1\n",
    "\n",
    "print(f'male: {count_m}, female: {count_f}, unknown: {count_u}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature - Drug Information\n",
    "\n",
    "This section describes process of identifying medicine and dosage used by authors.\n",
    "\n",
    "We first started by searching for most common drugs used for migraine.  We found that information on this [website](https://www.healthgrades.com/right-care/migraine-and-headache/12-drugs-commonly-prescribed-for-migraine)\n",
    "\n",
    "## Common Migraine Drugs\n",
    "\n",
    "- **Amitriptyline (Elavil)** is an antidepressant. The dosing ranges from once a day up to four times a day. It belongs to a group of antidepressants called tricyclics. Drowsiness and sleepiness are very common with this group, so your doctor may recommend taking it at bedtime.\n",
    "- **Divalproex sodium extended-release (Depakote ER)** is an anticonvulsant. You take the extended-release tablet once a day. Taking it with food can help prevent stomach upset.\n",
    "- **Eletriptan (Relpax)** is a triptan. It is a tablet you take at the onset of your migraine symptoms. For triptans, your doctor will tell you how many tablets you can take in a 24 hour period.\n",
    "- **Metoprolol (Lopressor, Toprol XL)** is a beta blocker. It comes in both an immediate-release and an extended-release form.\n",
    "- **Propranolol extended-release (Inderal, Inderal LA, Inderal XL)** is another beta blocker. It comes in several forms, each with their own dosing. Talk with your doctor or pharmacist about how to take your medicine.\n",
    "- **Rizatriptan (Maxalt)** is a triptan you use at the onset of symptoms. It comes as a tablet and a disintegrating tablet, which melts in your mouth without water.\n",
    "- **Sumatriptan (Imitrex)** is another triptan. It comes in several forms, including a tablet, injection, and nasal spray.\n",
    "- **Topiramate (Topamax, Trokendi XR)** is an anticonvulsant. It comes in a regular-release tablet and an extended-release capsule. You can take either kind with or without food.\n",
    "- **Venlafaxine (Effexor, Effexor XR)** is an antidepressant. You take both the tablet and the extended-release capsule with food. Stomach upset, headache, and appetite loss are common side effects.\n",
    "- **Zolmitriptan (Zomig)** is another triptan. It comes as a tablet, disintegrating table, and nasal spray.\n",
    "- **OnabotulinumtoxinA (Botox)** is a botulinum toxin that, when injected into areas of the face and scalp, can prevent the brain's pain response from activating. This stops migraine attacks before they occur.\n",
    "- **Erenumab (Aimovig)** is a CGRP blocker. It's given by self-injection once a month.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we created a list of drugs and added some additional drugs we saw in Reddit posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_list = [\n",
    "    'Amitriptyline',\n",
    "    'Elavil',\n",
    "    'Divalproex',\n",
    "    'Depakote',\n",
    "    'Eletriptan',\n",
    "    'Relpax',\n",
    "    'triptan',\n",
    "    'Metoprolol',\n",
    "    'Lopressor',\n",
    "    'Toprol',\n",
    "    'Propranolol',\n",
    "    'Inderal',\n",
    "    'beta blocker',\n",
    "    'Rizatriptan',\n",
    "    'Maxalt',\n",
    "    'Sumatriptan',\n",
    "    'Imitrex',\n",
    "    'Topiramate',\n",
    "    'Topamax',\n",
    "    'Trokendi',\n",
    "    'Venlafaxine',\n",
    "    'Effexor',\n",
    "    'Zolmitriptan',\n",
    "    'Zomig',\n",
    "    'OnabotulinumtoxinA',\n",
    "    'Botox',\n",
    "    'Erenumab',\n",
    "    'Aimovig',\n",
    "    'CGRP',\n",
    "    'Nurtec',  # found in the subreddit post\n",
    "    'Topomax',  # popular misspelling of Topamax,\n",
    "    'nortiptyline',  # found in the subreddit post\n",
    "    'metoclopramide',  # found in the subreddit post\n",
    "    'caffeine pill',  # found in the subreddit posts_and_comments\n",
    "    'naproxen',\n",
    "    'magnesium',\n",
    "    'Delta 8',\n",
    "    'Aimovig',\n",
    "    'sulfate',\n",
    "    'Xanax',\n",
    "    'amitryptiline',\n",
    "    'Amoxicillin'\n",
    "]\n",
    "\n",
    "# drug_list = set([s.lower() for s in drug_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Medicine Patterns\n",
    "\n",
    "Manually sampling above output we found following patterns to base our regex expressions on:\n",
    "\n",
    "- 75mg topamax daily\n",
    "- Recently been prescribed 25mg topiramate to take one a day before bed\n",
    "- I'm on 50mg and feel no effect at all\n",
    "- I'm on 50mg and dont feel completely wrecked the next day. But I also have a sleep disorder that benefits from amitriptyline making me tired at night\n",
    "- I’m currently on daily 40mg of Propranolol\n",
    "- my current amitryptiline dose (50mg)\n",
    "- prescribed me 50mg amitriptyline\n",
    "- I take 2 x 600 mg caps of magnesium\n",
    "- I take 10mg of edible Delta 8\n",
    "- I was on 10mg which worked great for 6 months\n",
    "- Now I take 30 mg\n",
    "- It's a combination of sumatriptan 85 mg and naproxen sodium 500 mg\n",
    "- I use 50 mg with a triptan\n",
    "- I currently take 75mg daily\n",
    "- I'm at 20mg 3x a day now\n",
    "- I started Aimovig in July 2018 at the 70mg dose\n",
    "- I take 50mg daily\n",
    "- She said 875mg of Amoxicillin\n",
    "- I take a total of 2400mg/day: 900mg/600mg/900mg.\n",
    "- it 80mg twice a day\n",
    "- Years ago i took 900mg three times a day\n",
    "- 300mg 3x a day\n",
    "- sulfate 325 mg twice daily\n",
    "- I took .5 mg of Xanax\n",
    "- my doc prescribed me 10mg of amitriptyline nightly\n",
    "- my dose is 2x 25mg\n",
    "- Topamax took about a month for me (at 50 mg)\n",
    "- Mine comes in 2.5mg.\n",
    "- but I take 250mg/day\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_drug_sentences = [\n",
    "    '75mg topamax daily',\n",
    "    'Recently been prescribed 25mg topiramate to take one a day before bed',\n",
    "    \"I'm on 50mg Topomax and feel no effect at all\",\n",
    "    \"I'm on 50mg Topomax and dont feel completely wrecked the next day. But I also have a sleep disorder that benefits from amitriptyline making me tired at night\",\n",
    "    'I’m currently on daily 40mg of Propranolol',\n",
    "    'my current amitryptiline dose (50mg)',\n",
    "    'prescribed me 50mg amitriptyline',\n",
    "    'I take 2 x 600 mg caps of magnesium',\n",
    "    'I take 10mg of edible Delta 8',\n",
    "    'I was on 10mg of Topomax which worked great for 6 months',\n",
    "    'Now I take 30 mg of Topomax',\n",
    "    'It\\'s a combination of sumatriptan 85 mg and naproxen sodium 500 mg',\n",
    "    'I use 50 mg with a triptan',\n",
    "    'I currently take Topomax 75mg daily',\n",
    "    'I\\'m on Topomax at 20mg 3x a day now',\n",
    "    'I started Aimovig in July 2018 at the 70mg dose',\n",
    "    'I take 50mg daily of Topomax',\n",
    "    'She said 875mg of Amoxicillin',\n",
    "    'I take Topomax a total of 2400mg/day: 900mg/600mg/900mg.',\n",
    "    'Topomax 80mg twice a day',\n",
    "    'Years ago i took Topomax 900mg three times a day',\n",
    "    'Topomax 300mg 3x a day',\n",
    "    'sulfate 325 mg twice daily',\n",
    "    'I took .5 mg of Xanax',\n",
    "    'my doc prescribed me 10mg of amitriptyline nightly',\n",
    "    'my dose of Aimovig is 2x 25mg',\n",
    "    'Topamax took about a month for me (at 50 mg)',\n",
    "    'Mine Topamax comes in 2.5mg.',\n",
    "    'but I take 250mg/day of Xanax'\n",
    "]\n",
    "\n",
    "invalid_drug_sentences = [\n",
    "    'I took .5 days of vaction',\n",
    "    'my doc prescribed me 10 days of rest',\n",
    "    'my car is 25kg heavier',\n",
    "    '50 mg of stuff',\n",
    "    'Mine Topamax comes in 2-5 weeks.'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of regex patterns is a bit more complex than previous one as we needed to store regex group indexes for dosage and quantity as they can appear at different positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regex patterns\n",
    "drug_matchers = [\n",
    "    {\n",
    "        'regex': re.compile('([0-9]x).*([0-9]+\\.?[0-9]+mg|[0-9]+\\.?[0-9]+\\smg|\\.?[0-9]+mg|\\.?[0-9]+\\smg)', flags=re.IGNORECASE),\n",
    "        'dosage_group': 2,\n",
    "        'qty_group': 1\n",
    "    },\n",
    "    {\n",
    "        'regex': re.compile('([0-9]+\\.?[0-9]+mg|[0-9]+\\.?[0-9]+\\smg|\\.?[0-9]+mg|\\.?[0-9]+\\smg).*([0-9]x)', flags=re.IGNORECASE),\n",
    "        'dosage_group': 1,\n",
    "        'qty_group': 2\n",
    "    },\n",
    "    {\n",
    "        'regex': re.compile('([0-9]+\\.?[0-9]+mg|[0-9]+\\.?[0-9]+\\smg|\\.?[0-9]+mg|\\.?[0-9]+\\smg).*(three times a day|four times a day|twice a day|one a day|twice daily)', flags=re.IGNORECASE),\n",
    "        'dosage_group': 1,\n",
    "        'qty_group': 2\n",
    "    },\n",
    "    {\n",
    "        'regex': re.compile('([0-9]+mg|[0-9]+\\smg).*(nightly|daily|dose|day)', flags=re.IGNORECASE),\n",
    "        'dosage_group': 1,\n",
    "        'qty_group': 2\n",
    "    },\n",
    "    {\n",
    "        'regex': re.compile('([0-9]+\\.?[0-9]+mg|[0-9]+\\.?[0-9]+\\smg|\\.?[0-9]+mg|\\.?[0-9]+\\smg)', flags=re.IGNORECASE),\n",
    "        'dosage_group': 1,\n",
    "        'qty_group': -1\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Medicine discovery functions\n",
    "def normalize_qty(qty_text):\n",
    "    if qty_text == 'daily' or qty_text == 'dose' or qty_text == 'day' or qty_text == 'one a day' or qty_text == '1x':\n",
    "        return '1x'\n",
    "\n",
    "    if qty_text == 'twice daily' or qty_text == 'twice a day':\n",
    "        return '2x'\n",
    "\n",
    "    if qty_text == 'three times a day':\n",
    "        return '3x'\n",
    "\n",
    "    return qty_text\n",
    "\n",
    "def find_medicine_name(text):\n",
    "    meds_matched = []\n",
    "    for drug in drug_list:\n",
    "        if re.search(drug, text, re.IGNORECASE):\n",
    "            meds_matched.append(drug)\n",
    "    return meds_matched\n",
    "\n",
    "def find_dosage(reg_res, matcher):\n",
    "    if matcher['qty_group'] == -1:\n",
    "        qty = '1x'\n",
    "    else:\n",
    "        qty = normalize_qty(reg_res.group(matcher['qty_group']))\n",
    "    return reg_res.group(matcher['dosage_group']), qty\n",
    "\n",
    "def discover_medicine_dosage(matchers):\n",
    "    def process_medicine_dosage(text):\n",
    "        for matcher in matchers:\n",
    "            if (reg_res := matcher['regex'].search(text)):\n",
    "                dosage, qty = find_dosage(reg_res, matcher)\n",
    "                if dosage:\n",
    "                    med = find_medicine_name(text)\n",
    "                    if med:\n",
    "                        return (\n",
    "                            med[0],\n",
    "                            dosage,\n",
    "                            qty\n",
    "                        )\n",
    "\n",
    "        return 'unknown', 'unknown', 'unknown'\n",
    "    return process_medicine_dosage\n",
    "\n",
    "find_medicine_dosage = discover_medicine_dosage(drug_matchers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_female_matchers (__main__.TestGenderDiscovery) ... ok\n",
      "test_male_matchers (__main__.TestGenderDiscovery) ... ok\n",
      "test_dosage_matchers (__main__.TestMedicineDosageDiscovery) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.007s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "# Unit tests\n",
    "def is_dosage_found(result):\n",
    "    med, dosage, qty = result\n",
    "    if med != 'unknown' and dosage != 'unknown' and qty != 'unknown':\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "class TestMedicineDosageDiscovery(unittest.TestCase):\n",
    "    def test_dosage_matchers(self):\n",
    "        self.assertTrue(all([is_dosage_found(find_medicine_dosage(text)) for text in sample_drug_sentences]))\n",
    "        self.assertFalse(all([is_dosage_found(find_medicine_dosage(text)) for text in invalid_drug_sentences]))\n",
    "\n",
    "res = unittest.main(argv=[''], verbosity=3, exit=False)\n",
    "assert len(res.result.failures) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run `find_medicine_dosage` function to find all entries in posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_medicine_in_posts(idx):\n",
    "    medicine_idx = copy.deepcopy(idx)\n",
    "    def process_entry(author, text):\n",
    "        med, dosage, qty = find_medicine_dosage(text)\n",
    "        medicine_idx[author] = {\n",
    "            'medicine': med,\n",
    "            'dosage': dosage,\n",
    "            'qty': qty\n",
    "        }\n",
    "\n",
    "    posts_and_commnets.apply(lambda x: process_entry(x['Author'], x['Text']), axis=1)\n",
    "    return medicine_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41209"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_index = identify_medicine_in_posts(author_index)\n",
    "len(author_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entries with medicine dosage: 1044\n"
     ]
    }
   ],
   "source": [
    "count_medicine = 0\n",
    "\n",
    "for _, v in author_index.items():\n",
    "    if v['medicine'] != 'unknown':\n",
    "        count_medicine += 1\n",
    "\n",
    "print(f'entries with medicine dosage: {count_medicine}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature - Suicidal Thoughts\n",
    "\n",
    "This section attempts to identify all of the authors that had suicidal thoughts.\n",
    "\n",
    "Following is the list of sample sentences talking about suicide and they will serve as a test sentences and patterns for creating regex expression to retrieve information on suicidal thoughts.\n",
    "\n",
    "Regex expression are divided into positive and negative.\n",
    "With these sentences it is important not to pick up negative sentences that would mean the exact opposite to what we are trying to detect.\n",
    "\n",
    "For example, we want to capture `I have suicidal thoughts` BUT we don't want to capture `I don't have suicidal thoughts`.  For this reason we will create regex set for capturing the negative sentences as well so that we can eliminate them from consideration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "suicide_sample_sentences = [\n",
    "    'Had suicidal thoughts',\n",
    "    'made me think a lot about suicide',\n",
    "    'I still thought about suicide',\n",
    "    'Suicide ideation',\n",
    "    'suicidal ideations',\n",
    "    'The “intrusive thoughts” and experiencing life far away'\n",
    "    'I had felt suicidal',\n",
    "    'feeling sad/suicidal',\n",
    "    'it made me wildly suicidal',\n",
    "    'I have been extremely suicidal',\n",
    "    'i also have been extremely suicidal',\n",
    "    'and then attempted suicide to stop the pain',\n",
    "    'my near suicide attempt',\n",
    "    'Depression and suicide thoughts are unbearable for me',\n",
    "    'I was having suicidal thoughts',\n",
    "    'I self harm and have suicidal thoughts',\n",
    "    'just made me suicidal',\n",
    "    'I was so suicidal',\n",
    "    'made me legitimately suicidal',\n",
    "    'Had suicidal thoughts',\n",
    "    'I still thought about suicide',\n",
    "    'made me think a lot about suicide'\n",
    "]\n",
    "\n",
    "neg_suicide_sample_sentences = [\n",
    "    'I am not suicidal',\n",
    "    'I have never been suicidal'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regex expressions\n",
    "positive_suicide_matchers = [\n",
    "    re.compile('(am|have|had|felt|having|me|was|been|think|about|feeling).*(suicidal|suicide)', re.IGNORECASE),\n",
    "    re.compile('(my near|made me|have been|thought about|).*(suicidal|suicide)', re.IGNORECASE)\n",
    "]\n",
    "\n",
    "negative_suicide_matchers = [\n",
    "    re.compile('(am|have|had|felt|having|me|was|been|think|about|feeling) (not|never).*(suicidal|suicide)', re.IGNORECASE),\n",
    "    re.compile('(my near|made me|have been|thought about|) (not|never).*(suicidal|suicide)', re.IGNORECASE)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_for_suicide(text):\n",
    "    return any([matcher.search(text) for matcher in positive_suicide_matchers]) \\\n",
    "        and not any([matcher.search(text) for matcher in negative_suicide_matchers])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_female_matchers (__main__.TestGenderDiscovery) ... ok\n",
      "test_male_matchers (__main__.TestGenderDiscovery) ... ok\n",
      "test_dosage_matchers (__main__.TestMedicineDosageDiscovery) ... ok\n",
      "test_suicidal_matchers (__main__.TestSuicidalThoughtsDiscovery) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.010s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "# Unit tests\n",
    "class TestSuicidalThoughtsDiscovery(unittest.TestCase):\n",
    "    def test_suicidal_matchers(self):\n",
    "        self.assertTrue(all([search_for_suicide(text) for text in suicide_sample_sentences]))\n",
    "        self.assertFalse(all([search_for_suicide(text) for text in neg_suicide_sample_sentences]))\n",
    "\n",
    "res = unittest.main(argv=[''], verbosity=3, exit=False)\n",
    "assert len(res.result.failures) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_suicidal_thoughts_in_posts(idx):\n",
    "    suicidal_thoughts_idx = copy.deepcopy(idx)\n",
    "    def process_entry(author, text):\n",
    "        if search_for_suicide(text):\n",
    "            suicidal_thoughts_idx[author] = { 'suicidal': 'yes' }\n",
    "        else:\n",
    "            suicidal_thoughts_idx[author] = { 'suicidal': 'no' }\n",
    "\n",
    "    posts_and_commnets.apply(lambda x: process_entry(x['Author'], x['Text']), axis=1)\n",
    "    return suicidal_thoughts_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41209"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_index = identify_suicidal_thoughts_in_posts(author_index)\n",
    "len(author_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authors with with suicidal thoughts: 139\n"
     ]
    }
   ],
   "source": [
    "total_suicidal = 0\n",
    "\n",
    "for _, v in author_index.items():\n",
    "    if v['suicidal'] == 'yes':\n",
    "        total_suicidal += 1\n",
    "\n",
    "print(f'Authors with with suicidal thoughts: {total_suicidal}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "043ded0200596b90969cdaf78db8cc3255494a426d99ef977fa69e36f146e9e2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit ('migraine-data-reddit-WM5Df_6q-py3.9': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
